{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Summarizer_Batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthik-Ragunath/Deep_Learning_Notebooks/blob/master/Summarizer_Batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLeh7AEMuIT"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCmbKbx7T12u",
        "outputId": "8f4148f5-bcdd-4a13-b610-df0230700b1a"
      },
      "source": [
        "# S: Symbol that shows starting of decoding input\n",
        "# E: Symbol that shows starting of decoding output\n",
        "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, n_class)] # n_class represents one hot encoding length\n",
        "    # outer list of dim 1\n",
        "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, one_hot_encoding_length)]\n",
        "    # outer list is of dimension 1\n",
        "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
        "    print('output_batch:', output_batch)\n",
        "    print('target_batch:', target_batch)\n",
        "    # returns dimension - [[word_len]]\n",
        "    # here too outer list of size 1\n",
        "\n",
        "    # make tensor\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3) \n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        print(\"Hidden Layer Size:\", n_hidden)\n",
        "        # Linear for attention\n",
        "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
        "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
        "\n",
        "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
        "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "\n",
        "        # enc_outputs : [n_step (sequence_len), batch_size, num_directions(=1) * n_hidden], matrix F\n",
        "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden) \n",
        "\n",
        "        trained_attn = []\n",
        "        hidden = enc_hidden\n",
        "        n_step = len(dec_inputs) # n_step - sequence_length\n",
        "        model = torch.empty([n_step, 1, n_class]) # same torch.empty(n_step, 1, n_class) - gives tensor of shape (seq_len, 1, input_feature_size)\n",
        "\n",
        "        # If there are multiple batches just make sure to add an outer for loop\n",
        "        # to traverse through different batches and to maintain 3 dimensions, use unsqueeze(batch_dim)\n",
        "        for i in range(n_step):  # each time step\n",
        "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
        "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden) # unsqueezing is done to maintain input_shape - shape maintained = (1, batch_size, n_class)\n",
        "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step] # to compute impact of rest of timestamps on one timestamp, \n",
        "                                                                                                         # thats why decoder output is 1 element (unsqueezed) and encoder output is in list \n",
        "            trained_attn.append(attn_weights.squeeze().data.numpy()) # (1,1,num_steps) gets squeezed into numpy array of size (num_steps) where num_steps = sequence_len or time_stamps\n",
        "\n",
        "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
        "            context = attn_weights.bmm(enc_outputs.transpose(0, 1)) # performing batch matrix multiplication\n",
        "            # (1,1,seq_len) * (seq_len, batch_size, n_hidden*n_directions(=1)).transpose(0,1) where n_class reders to features of input based on which one hot encoding is done\n",
        "            # (1,1,seq_len) * (batch_size, seq_len, n_hidden*n_directions(=1)) - we are considering only one batch here, therefore,\n",
        "            # (1,1,seq_len) * (1, seq_len, num_dirns(=1)*n_hidden) = (1, 1, num_dirns(=1)*n_hidden)\n",
        "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            # after squeezing [n_step(=1),batch_size(=1), num_directions(=1)*n_hidden] in 0th dimension - [batch_size(=1), num_directions(=1)*n_hidden]  \n",
        "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
        "            # after squeezing [1,1, num_dirns(=1)*n_hidden] in 0th dimension - [1,  num_dirns(=1)*n_hidden]\n",
        "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
        "            # torch.cat return (1, (num_directions(=1) * n_hidden) + (num_directions(=1) * n_hidden)) = (1, 2 * num_directions(=1) * n_hidden)\n",
        "            # (1, 2 * num_directions(=1) * n_hidden) * (2*num_directions(=1)*n_hidden, n_class) # n_class represents input features used for one hot encoding\n",
        "            # which will return (1, n_class)\n",
        "\n",
        "        # make model shape [n_step, n_class]\n",
        "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
        "        # model overall shape - [seq_len, 1, n_class]\n",
        "        # [seq_len, 1, n_class].transpose(0, 1) returns shape - [1, seq_len, n_class]\n",
        "        # [seq_len, 1, n_class] squeezing on dimension 0 returns (seq_len, n_class) # seq_len is same as n_step or number_of_timestamps\n",
        "\n",
        "\n",
        "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
        "        n_step = len(enc_outputs) # n_step = seq_len\n",
        "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
        "        # dec\n",
        "        for i in range(n_step):\n",
        "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
        "\n",
        "        # Normalize scores to weights in range 0 to 1\n",
        "        return F.softmax(attn_scores).view(1, 1, -1) # gets softmax output from list of size seq_len (time_stamps)\n",
        "        # returns dimension of size (1,1,seq_len)\n",
        "\n",
        "\n",
        "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
        "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
        "        # attn = nn.Linear(n_hidden, n_hidden) - enc_output = (batch_size, n_hidden * num_dirns) - dec_output = (Batch_size, n_hidden * num_dirns)\n",
        "        # (batch_size, n_hidden*num_dirns) * (n_hidden, n_hidden) = (batch_size, n_hidden)\n",
        "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
        "        # .view(-1) unravels the last dimension which will result in 2 dimesnional tensor becoming 1 dimensional\n",
        "        # .view(-1) will therefore return dimension - vector of dimension batch_size * n_hidden\n",
        "        # dot product will be scalar\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_step = 5 # number of cells(= number of Step)\n",
        "    n_hidden = 128 # number of hidden units in one cell\n",
        "\n",
        "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
        "\n",
        "    word_list = \" \".join(sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "\n",
        "    # print(word_list, word_dict, number_dict)\n",
        "    n_class = len(word_dict)  # vocab list\n",
        "\n",
        "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "    hidden = torch.zeros(1, 1, n_hidden)\n",
        "    # print('n_class:', n_class)\n",
        "    # print('*****************')\n",
        "    # print('hidden:', hidden)\n",
        "    # print('len hidden:', len(hidden[0][0]))\n",
        "\n",
        "    model = Attention()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    input_batch, output_batch, target_batch = make_batch()\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3)\n",
        "\n",
        "    # # Train\n",
        "    for epoch in range(2000):\n",
        "        optimizer.zero_grad()\n",
        "        # clears gradients stored in .grad buffer from previous epoch\n",
        "        output, _ = model(input_batch, hidden, output_batch)\n",
        "        # invokes forward mehod and performs forward pass\n",
        "        loss = criterion(output, target_batch.squeeze(0))\n",
        "        # computing loss\n",
        "        if (epoch + 1) % 400 == 0:\n",
        "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "        loss.backward()\n",
        "        # back-propagates the gradient error to previous layers\n",
        "        optimizer.step()\n",
        "        # updates the parameters\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 128\n",
            "output_batch: [array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])]\n",
            "target_batch: [[5, 7, 10, 8, 0]]\n",
            "Epoch: 0400 cost = 0.000486\n",
            "Epoch: 0800 cost = 0.000159\n",
            "Epoch: 1200 cost = 0.000079\n",
            "Epoch: 1600 cost = 0.000047\n",
            "Epoch: 2000 cost = 0.000030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOVZr5k99kRO",
        "outputId": "4db81de6-8b52-44e4-8784-a44956ddfc93"
      },
      "source": [
        "number_dict"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'E',\n",
              " 1: 'mochte',\n",
              " 2: 'bier',\n",
              " 3: 'ein',\n",
              " 4: 'S',\n",
              " 5: 'i',\n",
              " 6: 'P',\n",
              " 7: 'want',\n",
              " 8: 'beer',\n",
              " 9: 'ich',\n",
              " 10: 'a'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvW5JE9foUP"
      },
      "source": [
        "    # # Test\n",
        "    # test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # test_batch = torch.FloatTensor(test_batch)\n",
        "    # predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    # predict = predict.data.max(1, keepdim=True)[1]\n",
        "    # print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNFUq-k4gO_U",
        "outputId": "d0fd2911-db5e-4f0b-abcb-bc830aea9fb4"
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # create one hot encoding\n",
        "    test_batch = torch.FloatTensor(test_batch)\n",
        "    # convert list of numpy arrays to tensor\n",
        "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    predict = predict.data.max(1, keepdim=True)[1]\n",
        "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "zqqUZEgsfpVY",
        "outputId": "514da2be-1168-4824-ede2-fe4a613ba73c"
      },
      "source": [
        "    # Show Attention\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(trained_attn, cmap='viridis')\n",
        "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
        "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAE2CAYAAADyN1APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARJ0lEQVR4nO3de7CcdX3H8fcHEsIQpFMUBwSFCt4YLy2Gi4qSDrRQHTsdZXRUUHHGgJSKipdpLWpHndTbgBVBUxmjHWzV0ZGKdyoZdMotWKs2UFDkEq7hfgmEAN/+sU/ssv4Sck6y51nOeb9mdk7Os8/u833O5rx5nmdPOKkqJEmPtk3fA0jSJDKOktRgHCWpwThKUoNxlKQG4yhJDcZxSJLlSc7ZjPX2SlJJFs3EXH3o9u/IvufYUo+n/UiyIslp071fW9e8vgeYMCcC6XuIx4MkewG/BfavqpX9TrNJuwF39D3EVvIqYH3fQ4xDkuXAm7pPHwKuA74JfLCq7utjJuM4pKru6nsGbV1VdVPfM2wtVXX7lj5HkvlVNamBPRc4GpgPvBT4ArAQeFsfw3haPWT4tDoDJyW5Msm6JKuTLB15yJ5JfpRkbZJVSf5sTHOtSHJGkk8luT3JmiQnJlmQ5LNJ7kxybZKjhx7zvCTnJrm/e8zyJH8w8rxvSvLLbv9uTvKlkU3vnOTrSe5LclWSo4bu+2338ZLu1HXF0PMe0309HkhyRZJ3JhnL37XudXpvkt90+/rL4TmHT6uHLoe8eiZet2mal+TTSe7obp/Y8LUbPa1Osl2Sj3V/N9cmuSTJ4UP3L+729+VJLk7yIHB4Y5uTYl1V3VRV11XVV4CzgL/qbZqq8tbdgOXAOd2flwJ3Am8B9gFeBBzf3bcXUMDlwCuBZwBfAm4DdhzDXCuAu4EPdds6qdv+9xhcCtgH+DCwjsFp5ELgBuBbwPOAQ4ArgG8MPeexwAPAu4BnAS8E3jN0fwGrgaO6518KPAg8rbt//26dw4FdgZ275W8FbgSOBP6o+/rcBJwwptfso8D/Akd023s9cB/wiqH9OLKP122ar/M9wGeAZwOvAe4C3jV0/2lD658FXAi8DHg6cEL3Gr2gu39xt7+/BP68W2eXvvfzsb73hpb9E3BrbzP1/UWZpNuGFwjYsQvHcRtZb8M32bFDy3bvlh08hrlWABcMfR5gDfDvQ8vmd98YR3aBugt4wtD9G75R9uk+Xw384ya2WcDSoc/nAWuBo0a+BotGHnctcPTIsncAq8bwdVkI3A+8dGT5qcB3h/ZjNI4z8rpN83W+AsjQsr8HVg/df1r3572BR+j+YzW0/reA00de81f3vW+bse+PiiNwAHAr8NW+ZvKaY9u+wALgPx5jvV8M/fmG7uOTxzLR0LaqqpLcwuCIYMOy9Unu6La/D/CLqrpn6PH/yeCbad8kdzOIwmbvX1U9lGQNm9i/JLsATwU+n+SMobvmMZ43uvYFtge+n2T4/6AyH7h6E4+byddtqi6srg6dC4APJ9lpZL39GHxNVyWP+tIuAH48su4kv2E27Igk9zL4+zIfOBv4m76GMY5b5ncXtrtgwfiu445eRK+NLHus7U/lf8M01effcN9xDGI8bhu290oGR6zDNvWmw0y+buOyDYPXY39+f1/vH/m8l3d7p+F8YAmD/bmhen7jyDi2Xcbg+t2hwJU9zzIdlwFvSfKEoaPHFzP4hrqsqm5Jcj2D/fvRNLfxYPdx2w0LqurmJDcAe1fVl6f5vFOxisHrtGdVjR4tPV4dmCRDR48HMQjF3SNHiP/F4Mhx16o6b6aHHJO1VfXrvofYwDg2VNU9ST4NLE2yjsF/0Z4IvLCqztj0oyfCWcA/AF9O8gHgD4HPA98c+sv3UeCUJDcD3wF2AA6tqk9t5jZuYXCEcniSq4EHavCjUB8EPpPkTuC7DE6P9gN2r6rRd/u3SPc6fRL4ZAblOJ/B9eKDgEeqatnW3N4MeQpwapLTGbyZ9h7gI6MrVdUVSc4Clic5CfgZsDOD64xXVdU3Z27k2ck4btzfMvjh4ZOBPYCbgZk4GtpiVbW2+5GOU4GLGby5dDaDd7Y3rHNG96MdJwEfA25nELPN3cZDSd4OfIBBEH8CLK6qLyS5j8E39VIGAf0fYFz/suNkBq/Nu4EzGLyr/3Pg42Pa3ridxeBo/CIGp81nAqdsZN1jgPcz2Nc9GLyGFwOz5UiyV3n0tV9JEjz+LkJL0owwjpLUYBwlqcE4SlKDcZSkBuMoSQ3GcYqSLOl7hnGYrfsFs3ff3K/xMo5TNxEv3BjM1v2C2btv7tcYGUdJapgV/0Jmuyyo7Vk4I9tazzrms2BGtjWTZut+wezdt5ner2c+f+2MbGfNbQ+zyxO3fewVt5JLf7Hu1qraZXT5rPi31duzkANzaN9jSLPaD37w875HGIttd/v1Na3lnlZLUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhomOo5Jlic5p+85JM09k/7bB08E0vcQkuaeiY5jVd3V9wyS5iZPqyWpYaLjKEl9mejT6k1JsgRYArA9O/Q8jaTZ5nF75FhVy6pqUVUtms+CvseRNMs8buMoSeNkHCWpwThKUoNxlKSGiX63uqre3PcMkuYmjxwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkhon+HTLS407S9wRj83A90vcIM8ojR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGiYyjklWJDmt7zkkzV0TGUdJ6ttjxjHJEUnuSTKv+3yfJJXkc0PrfCTJuUm2TXJmkt8muT/JlUnem2SboXWXJzknyYlJrk9yR5IvJtlhw/3AIcBfd9upJHtt5f2WpE2atxnr/BTYHlgEXAgsBm7tPm6wGPg+g9heD7wGWAMcACwDbgPOHFr/pcCNwGHAU4GvAVcAS4ETgWcClwN/162/Zmq7JUlb5jGPHKvqXuBS4E+7RYuB04A9k+zWHfHtD6yoqvVV9YGquqSqrq6qrwGfA1438rR3A8dV1WVV9UPg68Ch3fbuAh4E1lbVTd3t4dG5kixJsjLJyvWsm86+S9JGbe41xxX8/5HiIcD3gIu6ZS8GHgIuBkhyXBetNUnuBd4JPG3k+VaNBO8G4MlTGbyqllXVoqpaNJ8FU3moJD2mqcTxJUmeA+zE4EhyBYOjycXABVX1YJLXAqcCy4HDgT8GTge2G3m+9SOf1xRmkaSx25xrjjC47rgAeC/w06p6OMkK4J+BmxlcbwQ4GLioqn73YzhJ9p7GXA8C207jcZK0VWzW0drQdcejgPO6xRcCewAHMTiKhMGbKvsl+Yskz0hyMoPT8Km6GjggyV5JnjT8brckzYSpRGcFgyPNFQBV9QCD647r6K43Ap9n8M7zV4BLgL2AT01jrk8yOHpcxeCd6tFrlpI0VqmqvmfYYjtl5zowh/Y9hgRJ3xOMzXdXX9r3CGOx3VOuurSqFo0u93RVkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktSwub+3Wj3YZuHCvkcYm3+5/Id9jzAWb3jqS/oeYWxevvt+fY8wJlc1l3rkKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNExXHJEck+UmSO5LcnuQHSZ7T91yS5p6JiiOwEDgVOABYDNwFfDvJdqMrJlmSZGWSletZN7NTSpr15vU9wLCq+sbw50mOAe5mEMufjqy7DFgGsFN2rpmaUdLcMFFHjkn2TvKVJL9JcjdwM4MZn9bzaJLmmIk6cgTOAVYDxwLXAw8Bq4DfO62WpHGamDgmeSLwbOD4qjqvW7YfEzSjpLljksJzB3Ar8NYk1wG7A59gcPQoSTNqYq45VtUjwGuB5wO/Aj4LnAy+FS1p5k3SkSNV9WPguSOLd+xjFklz28QcOUrSJDGOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpYaJ+h4we7ZH77ut7hLF545/8Zd8jjMXp15zd9whjc/yeB/c9wozyyFGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSw5TimGRFktPGNYwkTQqPHCWpYeLjmGS7vmeQNPdMJ47zknw6yR3d7RNJtoFByJJ8LMnqJGuTXJLk8OEHJ9k3yXeS3JPkliT/mmTXofuXJzknyfuSrAZWb9kuStLUTSeOb+ge9yLgWGAJ8I7uvi8ChwCvB54LfAn4dpIXACTZDTgf+BVwAHAYsCNw9obAdg4Bng8cARw6jRklaYvMm8ZjbgTeXlUFXJ7kmcC7kpwNvA7Yq6qu7dY9LclhDCJ6PPA24L+r6n0bnizJG4HbgUXAxd3iB4C3VNW6jQ2RZAmDMLM9O0xjNyRp46Zz5HhhF8YNLgB2Bw4GAqxKcu+GG/AKYO9u3RcCLxu5/7ruvr2HnvNXmwojQFUtq6pFVbVoPgumsRuStHHTOXLclAL2B9aPLL+/+7gN8B3g3Y3H3jz05/u28lySNCXTieOBSTJ09HgQcAODI8gAu1bVeRt57M+A1wDXVNVoQCVpYkzntPopwKlJnpXkSOA9wClVdQVwFrA8yZFJnp5kUZJ3J3lV99jPAn8AfDXJgd06hyVZluQJW2WPJGkrmM6R41nAtsBFDE6jzwRO6e47Bng/8HFgDwZvtFwMnAdQVTckeQmwFPg+sD1wLfBDYJPXGCVpJk0pjlW1eOjTExr3rwc+1N029hxXAkdu4v43T2UmSRqHif8XMpLUB+MoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIatvbvrZY2y8O33tb3CGNxwrMO63uEsfm3637c9whj8aQ92ss9cpSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqWFi4phkeZJq3C7sezZJc8+8vgcYcS5w9MiyB/sYRNLcNmlxXFdVN/U9hCRNzGm1JE2SSYvjEUnuHbl9rLVikiVJViZZuZ51Mz2npFlu0k6rzweWjCy7s7ViVS0DlgHslJ1rzHNJmmMmLY5rq+rXfQ8hSZN2Wi1JE2HSjhwXJNl1ZNnDVbWml2kkzVmTFsfDgBtHll0P7NHDLJLmsIk5ra6qN1dVGjfDKGnGTUwcJWmSGEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpIVXV9wxbLMka4JoZ2tyTgFtnaFszabbuF8zefXO/to49q2qX0YWzIo4zKcnKqlrU9xxb22zdL5i9++Z+jZen1ZLUYBwlqcE4Tt2yvgcYk9m6XzB79839GiOvOUpSg0eOktRgHCWpwThKUoNxlKQG4yhJDf8HDqh+n4LzNSkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S15G19GJOLsR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqtOuaaOLIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exn2HlcSOKwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsFPimC8OKm1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIlXX5F_w-T"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Qfr_bo_wwH"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WrZM_Oegk_W"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HznVRXWIo4QQ",
        "outputId": "405f00c7-c1b2-4191-e35b-3b540b4f68e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOJrrIx6uEun"
      },
      "source": [
        "english_french_df = pd.read_csv('/content/drive/My Drive/UTD/Jessica Ouyang/English_French_translation_tab_delimited.csv', delimiter='\\t', index_col=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PNh_VVupuMgd",
        "outputId": "6c6df52a-175c-439e-fcdc-10e548014642"
      },
      "source": [
        "english_french_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
              "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Site map</td>\n",
              "      <td>Plan du site</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Feedback</td>\n",
              "      <td>Rétroaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Credits</td>\n",
              "      <td>Crédits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Français</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>Iqa e</td>\n",
              "      <td>de ie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>La</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ad S</td>\n",
              "      <td>Da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>or</td>\n",
              "      <td>Cerc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>P O</td>\n",
              "      <td>hit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     en                                                 fr\n",
              "0     Changing Lives | Changing Society | How It Wor...  Il a transformé notre vie | Il a transformé la...\n",
              "1                                              Site map                                       Plan du site\n",
              "2                                              Feedback                                        Rétroaction\n",
              "3                                               Credits                                            Crédits\n",
              "4                                              Français                                            English\n",
              "...                                                 ...                                                ...\n",
              "2995                                              Iqa e                                              de ie\n",
              "2996                                                 La                                                  T\n",
              "2997                                               ad S                                                 Da\n",
              "2998                                                 or                                               Cerc\n",
              "2999                                                P O                                                hit\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcgkkn6QUIVp",
        "outputId": "805e0b61-730a-4ba9-cc0e-c278d660a90a"
      },
      "source": [
        "english_french_df.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['en', 'fr'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUjEtn67UIR-"
      },
      "source": [
        "english_sentences = english_french_df['en']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo8YRo_BUIOZ"
      },
      "source": [
        "french_sentences = english_french_df['fr']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npjokVQ4UIKz",
        "outputId": "518b4790-cf44-429d-dffe-6f1193a23caa"
      },
      "source": [
        "french_sentence_list = []\n",
        "english_sentence_output_list = []\n",
        "english_sentence_target_list = []\n",
        "\n",
        "french_sentence_hack = []\n",
        "english_sentence_output_hack = []\n",
        "english_sentence_target_hack = []\n",
        "\n",
        "for index, (english_sentence, french_sentence) in enumerate(zip(english_sentences, french_sentences)):\n",
        "    try:\n",
        "        if english_sentence and french_sentence:\n",
        "            english_sentence_output_list.append(\"S \" + english_sentence)\n",
        "            english_sentence_target_list.append(english_sentence + \" E\")\n",
        "            french_sentence_list.append(french_sentence + \" P\")\n",
        "            if len(english_sentence.split()) == 4 and len(french_sentence.split()) == 4:\n",
        "                english_sentence_output_hack.append(\"S \" + english_sentence)\n",
        "                english_sentence_target_hack.append(english_sentence + \" E\")\n",
        "                french_sentence_hack.append(french_sentence + \" P\")\n",
        "    except Exception as e:\n",
        "        print(\"Error raised\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error raised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Q781r-UH-S",
        "outputId": "d18d4de7-4578-4e48-add3-609dbaa92734"
      },
      "source": [
        "print(english_sentence_output_list[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S Changing Lives | Changing Society | How It Works | Technology Drives Change Home | Concepts | Teachers | Search | Overview | Credits | HHCC Web | Reference | Feedback Virtual Museum of Canada Home Page', 'S Site map', 'S Feedback', 'S Credits', 'S Français', 'S What is light ?', 'S The white light spectrum Codes in the light The electromagnetic spectrum Emission spectra Absorption spectra Light-years Light pollution', 'S The sky of the first inhabitants A contemporary vison of the Universe Astronomy for everyone', 'S Cartoon', 'S Links']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRLc2ZfUH11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e25b39-c89e-4f1c-a211-e94b83b08599"
      },
      "source": [
        "len(english_sentence_output_hack)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ9fG85CUHnF"
      },
      "source": [
        "vocabulary_sentences = french_sentence_hack + english_sentence_output_hack + english_sentence_target_hack"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kb2Hs1Ygk5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c650a6-8edd-4267-8040-d51c555d9225"
      },
      "source": [
        "len(vocabulary_sentences), len(french_sentence_hack), len(english_sentence_output_hack), len(english_sentence_target_hack)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 27, 27, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_VPPvfxgk27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348fcc0c-b868-4f01-aa44-6981cb481084"
      },
      "source": [
        "french_sentence_list[:4]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Il a transformé notre vie | Il a transformé la société | Son fonctionnement | La technologie, moteur du changement Accueil | Concepts | Enseignants | Recherche | Aperçu | Collaborateurs | Web HHCC | Ressources | Commentaires Musée virtuel du Canada P',\n",
              " 'Plan du site P',\n",
              " 'Rétroaction P',\n",
              " 'Crédits P']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr87wmAm5v6y"
      },
      "source": [
        "word_list = \" \".join(vocabulary_sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHMAPSrz5v3z"
      },
      "source": [
        "n_class = len(word_dict)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S05eKDCU7lji"
      },
      "source": [
        "def make_batches():\n",
        "    french_one_hot_encoded = []\n",
        "    for sentence in french_sentence_hack:\n",
        "        sentence_one_hot_encoded = np.eye(n_class)[[word_dict[n] for n in sentence.split()]]\n",
        "        french_one_hot_encoded.append(sentence_one_hot_encoded)\n",
        "\n",
        "    english_sentence_output_one_hot = []\n",
        "    for sentence in english_sentence_output_hack:\n",
        "        sentence_one_hot_encoded = np.eye(n_class)[[word_dict[n] for n in sentence.split()]]\n",
        "        english_sentence_output_one_hot.append(sentence_one_hot_encoded)\n",
        "\n",
        "\n",
        "    english_sentence_target_one_hot = [[word_dict[n] for n in sentence.split()] for sentence in english_sentence_target_hack]\n",
        "    return torch.FloatTensor(french_one_hot_encoded), torch.FloatTensor(english_sentence_output_one_hot), torch.LongTensor(english_sentence_target_one_hot)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL1oKwOp7k6N",
        "outputId": "6915b817-860a-4412-fc39-81e094443527"
      },
      "source": [
        "input_batches, output_batches, target_batches = make_batches()\n",
        "print(input_batches.shape, output_batches.shape, target_batches.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([27, 5, 147]) torch.Size([27, 5, 147]) torch.Size([27, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtP4kjTF7kbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e050d4fb-4405-4e71-96f2-89244c3e23e6"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    n_step = 5 # number of cells(= number of Step)\n",
        "    n_hidden = 128 # number of hidden units in one cell\n",
        "\n",
        "    word_list = \" \".join(vocabulary_sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "\n",
        "    # print(word_list, word_dict, number_dict)\n",
        "    n_class = len(word_dict)  # vocab list\n",
        "\n",
        "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "    hidden = torch.zeros(1, 1, n_hidden)\n",
        "\n",
        "    model = Attention()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    input_batches, output_batches, target_batches = make_batches()\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3)\n",
        "\n",
        "    # # Train\n",
        "    for epoch in range(2000):\n",
        "        for input_batch, output_batch, target_batch in zip(input_batches, output_batches, target_batches):\n",
        "            input_batch = input_batch.unsqueeze(0)\n",
        "            output_batch = output_batch.unsqueeze(0)\n",
        "            target_batch = target_batch.unsqueeze(0)\n",
        "            optimizer.zero_grad()\n",
        "            # clears gradients stored in .grad buffer from previous epoch\n",
        "            output, _ = model(input_batch, hidden, output_batch)\n",
        "            # invokes forward mehod and performs forward pass\n",
        "            loss = criterion(output, target_batch.squeeze(0))\n",
        "            # computing loss\n",
        "            if (epoch + 1) % 400 == 0:\n",
        "                print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "            loss.backward()\n",
        "            # back-propagates the gradient error to previous layers\n",
        "            optimizer.step()\n",
        "            # updates the parameters"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 128\n",
            "Epoch: 0400 cost = 0.000360\n",
            "Epoch: 0400 cost = 0.000208\n",
            "Epoch: 0400 cost = 0.000751\n",
            "Epoch: 0400 cost = 0.000767\n",
            "Epoch: 0400 cost = 0.000475\n",
            "Epoch: 0400 cost = 0.000606\n",
            "Epoch: 0400 cost = 0.000517\n",
            "Epoch: 0400 cost = 0.000486\n",
            "Epoch: 0400 cost = 0.000312\n",
            "Epoch: 0400 cost = 0.000171\n",
            "Epoch: 0400 cost = 0.000331\n",
            "Epoch: 0400 cost = 0.000382\n",
            "Epoch: 0400 cost = 0.000254\n",
            "Epoch: 0400 cost = 0.000440\n",
            "Epoch: 0400 cost = 0.000476\n",
            "Epoch: 0400 cost = 0.000447\n",
            "Epoch: 0400 cost = 0.000460\n",
            "Epoch: 0400 cost = 0.000334\n",
            "Epoch: 0400 cost = 0.000304\n",
            "Epoch: 0400 cost = 0.000357\n",
            "Epoch: 0400 cost = 0.000239\n",
            "Epoch: 0400 cost = 0.000208\n",
            "Epoch: 0400 cost = 0.000227\n",
            "Epoch: 0400 cost = 0.000218\n",
            "Epoch: 0400 cost = 0.000235\n",
            "Epoch: 0400 cost = 0.000185\n",
            "Epoch: 0400 cost = 0.000283\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000003\n",
            "Epoch: 0800 cost = 0.000003\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000002\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 0800 cost = 0.000001\n",
            "Epoch: 1200 cost = 0.000771\n",
            "Epoch: 1200 cost = 0.000082\n",
            "Epoch: 1200 cost = 0.143747\n",
            "Epoch: 1200 cost = 0.158666\n",
            "Epoch: 1200 cost = 0.027432\n",
            "Epoch: 1200 cost = 0.160356\n",
            "Epoch: 1200 cost = 0.029119\n",
            "Epoch: 1200 cost = 0.159479\n",
            "Epoch: 1200 cost = 0.000707\n",
            "Epoch: 1200 cost = 0.001062\n",
            "Epoch: 1200 cost = 0.002673\n",
            "Epoch: 1200 cost = 0.000403\n",
            "Epoch: 1200 cost = 0.000223\n",
            "Epoch: 1200 cost = 0.000680\n",
            "Epoch: 1200 cost = 0.158634\n",
            "Epoch: 1200 cost = 0.001491\n",
            "Epoch: 1200 cost = 0.163200\n",
            "Epoch: 1200 cost = 0.002067\n",
            "Epoch: 1200 cost = 0.000507\n",
            "Epoch: 1200 cost = 0.000510\n",
            "Epoch: 1200 cost = 0.000168\n",
            "Epoch: 1200 cost = 0.000178\n",
            "Epoch: 1200 cost = 0.000510\n",
            "Epoch: 1200 cost = 0.000376\n",
            "Epoch: 1200 cost = 0.000362\n",
            "Epoch: 1200 cost = 0.000153\n",
            "Epoch: 1200 cost = 0.000206\n",
            "Epoch: 1600 cost = 0.000005\n",
            "Epoch: 1600 cost = 0.000000\n",
            "Epoch: 1600 cost = 0.000020\n",
            "Epoch: 1600 cost = 0.000016\n",
            "Epoch: 1600 cost = 0.000013\n",
            "Epoch: 1600 cost = 0.000025\n",
            "Epoch: 1600 cost = 0.000013\n",
            "Epoch: 1600 cost = 0.000028\n",
            "Epoch: 1600 cost = 0.000008\n",
            "Epoch: 1600 cost = 0.000006\n",
            "Epoch: 1600 cost = 0.000011\n",
            "Epoch: 1600 cost = 0.000002\n",
            "Epoch: 1600 cost = 0.000003\n",
            "Epoch: 1600 cost = 0.000009\n",
            "Epoch: 1600 cost = 0.000030\n",
            "Epoch: 1600 cost = 0.000005\n",
            "Epoch: 1600 cost = 0.000028\n",
            "Epoch: 1600 cost = 0.000013\n",
            "Epoch: 1600 cost = 0.000002\n",
            "Epoch: 1600 cost = 0.000002\n",
            "Epoch: 1600 cost = 0.000001\n",
            "Epoch: 1600 cost = 0.000002\n",
            "Epoch: 1600 cost = 0.000003\n",
            "Epoch: 1600 cost = 0.000003\n",
            "Epoch: 1600 cost = 0.000002\n",
            "Epoch: 1600 cost = 0.000001\n",
            "Epoch: 1600 cost = 0.000001\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n",
            "Epoch: 2000 cost = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Dr2du-5vwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c7361e-5941-4bc9-fb17-1e0441b02a58"
      },
      "source": [
        "random_integer = (int)(torch.randint(low=1, high=27, size=(1,))[0])\n",
        "with torch.no_grad():\n",
        "    input_test_batch = input_batches[random_integer].unsqueeze(0)\n",
        "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # create one hot encoding\n",
        "    test_batch = torch.FloatTensor(test_batch)\n",
        "    # convert list of numpy arrays to tensor\n",
        "    predict, trained_attn = model(input_test_batch, hidden, test_batch)\n",
        "    predict = predict.data.max(1, keepdim=True)[1]\n",
        "    print(french_sentence_hack[random_integer], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectre d'émission du fer. P -> ['Emission', 'spectra', 'of', 'iron.', 'E']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEI8cln35vUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "6d47fbcc-43c0-4906-fa6c-973de9db8a4f"
      },
      "source": [
        "# Show Attention\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.matshow(trained_attn, cmap='viridis')\n",
        "ax.set_xticklabels([''] + french_sentence_hack[random_integer].split(), fontdict={'fontsize': 14})\n",
        "ax.set_yticklabels([''] + english_sentence_target_hack[random_integer].split(), fontdict={'fontsize': 14})\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF452yUnMqw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s02o_GBMqUY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew13wZkVMqQg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMSwhjzMqKf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xvyAQOZ5vKd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGxeliXgkzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyLONFZCgkwn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN-Py84ggkm8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4F4usaGgkZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afPYEL0mpv75"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)\n",
        "\n",
        "# rnn = nn.RNN(10, 20, 2) - # number_of_features = 10 (Used for one-hot encoding), hidden_size = 20 (output size), num_layers = 2\n",
        "# input = torch.randn(5, 3, 10) - # number_of_sequences = 5 (input_token_len [Intuitive number of cells]), number_of_batches = 3, input_size = 10 # num_features must be the same as input_size; used for one-hot encoding\n",
        "# h0 = torch.randn(2, 3, 20) - # directions * num_layers = 2, number_of_batches = 3, hidden_size = 20\n",
        "# output, hn = rnn(input, h0) - # output - (L,N,D∗Hout) - (num_sequences = 5, number_of_batches = 3, D*Hout (Dimension * Hidden_Size) = 1*20), hn - (D∗num_layers - (1*2), number_of_batches - 3, Hout (Hidden Size) - 20) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJvVBkPRp4yd",
        "outputId": "fd081349-9bc4-4b7f-b905-fda9155be74b"
      },
      "source": [
        "rnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(10, 20, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_TaKCC5vci",
        "outputId": "3eafae07-b1b5-482e-e02c-966bedfee9eb"
      },
      "source": [
        "input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0831e+00,  1.1682e+00,  2.0543e+00, -1.1602e+00,  1.0265e+00,\n",
              "           7.3769e-01,  4.0249e-01, -7.4208e-01,  2.1492e-01,  7.1503e-01],\n",
              "         [ 1.0265e+00,  2.8302e+00,  9.5309e-01,  8.8380e-01, -8.7740e-01,\n",
              "           1.3232e+00,  9.6722e-02, -1.0835e+00, -1.4574e+00, -9.0026e-01],\n",
              "         [ 2.1591e-01,  1.3157e-01, -6.3713e-01,  9.0262e-01, -5.4343e-01,\n",
              "           4.0305e-01, -1.2223e-02, -6.7788e-01, -8.7928e-01,  6.3687e-01]],\n",
              "\n",
              "        [[-8.1321e-02, -4.0574e-01,  2.0943e-01, -2.0276e-01,  6.2889e-01,\n",
              "          -1.9671e+00,  1.1834e-01, -7.1259e-01, -1.7655e+00,  2.6436e-01],\n",
              "         [ 7.2928e-01,  2.1325e+00,  1.2982e+00, -3.8353e-01, -5.0894e-01,\n",
              "          -3.8734e-01,  1.5055e+00, -2.0847e-01, -1.4812e-01,  7.0768e-01],\n",
              "         [-1.0223e+00, -2.0602e+00,  2.0781e+00, -9.0671e-01, -4.0895e-02,\n",
              "          -2.2190e-01,  3.0300e-01,  9.9097e-01, -5.6988e-01,  5.8662e-02]],\n",
              "\n",
              "        [[-3.6564e-01,  1.1822e+00,  1.0823e-01, -7.5445e-01, -1.0674e+00,\n",
              "           2.3805e+00,  2.1944e-01,  4.9921e-01, -5.2055e-01, -1.2934e+00],\n",
              "         [-1.1463e-02,  5.5235e-01, -1.7442e+00,  6.0407e-01, -9.9931e-01,\n",
              "          -2.2391e-01,  2.5706e-01,  1.7325e+00, -9.0848e-02,  1.2693e-01],\n",
              "         [-2.0427e+00,  2.3673e-01,  8.4605e-01,  2.2844e-01, -1.5144e+00,\n",
              "           1.8815e+00, -1.8379e+00,  1.1027e-01,  1.4516e+00, -9.5869e-01]],\n",
              "\n",
              "        [[ 7.0426e-01,  1.9117e+00, -1.1926e+00,  8.4414e-01,  1.2979e+00,\n",
              "          -2.6090e-01,  1.6821e+00,  2.2245e-01, -1.5491e-01,  3.3697e-02],\n",
              "         [-1.2981e+00, -6.4531e-02, -9.8550e-01, -1.2634e+00,  3.2740e-01,\n",
              "           2.6296e-01, -2.0712e-02, -8.2313e-01,  5.1711e-01,  7.4775e-01],\n",
              "         [ 1.0522e+00, -2.1027e+00,  1.0612e+00, -3.6456e-01,  7.4748e-04,\n",
              "          -1.0480e+00, -1.9398e-01,  5.5248e-02, -3.7262e-01, -7.2969e-01]],\n",
              "\n",
              "        [[-5.8658e-01,  6.9012e-01,  1.5063e+00,  3.9468e-01,  5.7959e-01,\n",
              "          -1.3423e+00,  1.0849e-01,  8.0357e-01,  1.3340e+00, -8.2865e-01],\n",
              "         [-1.6288e-01,  1.1537e+00, -5.7447e-01,  5.4543e-01, -6.2336e-01,\n",
              "           1.3390e+00,  7.6050e-01, -9.3769e-01,  3.7606e-01,  3.1286e-01],\n",
              "         [ 5.6045e-01, -9.9885e-01,  1.4292e-01,  9.9423e-01,  9.6206e-01,\n",
              "          -2.6770e-01, -1.6759e+00, -1.7291e+00,  8.8400e-01,  1.8094e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue9axnly5x6x",
        "outputId": "52c2614a-0ba7-4e90-8ab0-4cd223f2b68b"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqO8ugn50mR",
        "outputId": "d2fc145e-7fe4-4949-b2a0-7b5f769a14a0"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGfHQcfW54HR",
        "outputId": "6700dbc2-e2a6-4ce1-ecc7-1a88f5d74b15"
      },
      "source": [
        "hn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2yXZlbH6ShS"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr-Gpix064t1",
        "outputId": "3fe7ddd1-149e-4146-faeb-80525f1d336d"
      },
      "source": [
        "# linear layer\n",
        "m = nn.Linear(20, 30) # 20 - size of each input sample, 30 - size of each output sample\n",
        "input = torch.randn(128, 20) # 128 - No. of input samples, 20 - size of each input sample\n",
        "output = m(input) # (128 * 20) * (20 * 30) = (128 * 30) - matrix dimension\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydQPGauRQgxW",
        "outputId": "be0d26e8-f9a3-423b-9554-98fe3ece9394"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmEVciPFQi1l",
        "outputId": "18171992-ff6d-4893-dd04-787a4e9afcf5"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm_xGmMLQpIt",
        "outputId": "def36d6c-d75a-42c1-d833-8b266ff4c915"
      },
      "source": [
        "# nn.functional.linear\n",
        "input_matrix = torch.randn(128, 64)\n",
        "output_matrix = torch.randn(192, 64)\n",
        "bias = torch.ones(192)\n",
        "\n",
        "# bias got broadcasted\n",
        "\n",
        "print(input_matrix.shape)\n",
        "print(output_matrix.shape)\n",
        "print(bias.shape)\n",
        "\n",
        "m = nn.functional.linear(input_matrix, output_matrix, bias=bias) # (128 * 64) * (64 * 192) + (1 * 192)\n",
        "print(m.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64])\n",
            "torch.Size([192, 64])\n",
            "torch.Size([192])\n",
            "torch.Size([128, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hHqUNuTrxe"
      },
      "source": [
        "seq_len = 1\n",
        "input_feature_size = 2\n",
        "sample_model = torch.empty([seq_len, 1, input_feature_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au8RY99NXMZE",
        "outputId": "3f84c913-0a78-4536-c1be-604cdf308bdc"
      },
      "source": [
        "type(sample_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9XCS-iMXQGy",
        "outputId": "ae2653da-7f65-4bac-bce2-ac9e03f19cdd"
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unY0eqqWXjit",
        "outputId": "db921800-9c71-47f5-f808-091bd4b1be9d"
      },
      "source": [
        "sample_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBOm-nLTXSZq"
      },
      "source": [
        "sample_model = torch.empty(seq_len, 1, input_feature_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbkYtB75Xbj5",
        "outputId": "180bb55e-3a9e-4814-dcc3-8c5f3cbd1bda"
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9o8ME7eXech",
        "outputId": "0b4f7b30-352b-40b7-ab26-3950f613659c"
      },
      "source": [
        "sample_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8bJojtsXpZR",
        "outputId": "882c9f47-d095-43cd-9e9b-45ac87d9db18"
      },
      "source": [
        "seq_len = 120\n",
        "batches = 3\n",
        "num_input_features = 5 # vocab size for one hot encoding\n",
        "seq_index = 10\n",
        "enc_inputs = torch.randn((120, 3, 5))\n",
        "enc_inputs[seq_index].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "         [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "         [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt8P9IoBb3ed",
        "outputId": "33d2a04c-c0de-405c-8937-ea04dc4aae92"
      },
      "source": [
        "(enc_inputs[seq_index].squeeze(0)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ7ZEECycMVp",
        "outputId": "f332fbba-309c-4521-a8a1-bec55c76bf1e"
      },
      "source": [
        "enc_inputs[seq_index].squeeze(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "        [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "        [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeEN4zBDcXbA",
        "outputId": "651f5a0b-48ee-4bf4-b1c8-811aaa6f7bda"
      },
      "source": [
        "enc_inputs[seq_index].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqV9fZzOci2A",
        "outputId": "1e3c8f0d-7a4d-449c-93a0-7ab7da6a7550"
      },
      "source": [
        "# Performs batch matrix multiplication\n",
        "input = torch.randn(10, 3, 4)\n",
        "mat2 = torch.randn(10, 4, 5)\n",
        "res = torch.bmm(input, mat2)\n",
        "res.size()\n",
        "#torch.Size([10, 3, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c00V18FdkcTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f7ec43-0f27-40b4-b040-cae66d9639c5"
      },
      "source": [
        "input_1 = torch.randn(2,3)\n",
        "input_2 = torch.randn(2,3)\n",
        "view_1 = input_1.view(-1)\n",
        "view_2 = input_2.view(-1)\n",
        "print(view_1, view_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1577, -0.2166,  0.0382, -0.7249,  0.1684,  1.4514]) tensor([ 0.2352, -2.8680,  0.3145, -1.0206, -0.0357,  0.4765])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDfdyWFZMogs",
        "outputId": "89a74a02-ebdb-4280-808e-fad558cbd579"
      },
      "source": [
        "dot_product = torch.dot(view_1, view_2)\n",
        "dot_product"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.0959)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4f7qAW4NB66",
        "outputId": "0e48f084-3ebc-4020-c53b-0c5321325bb6"
      },
      "source": [
        "0.1577 * 0.2352 + -0.2166 * -2.8680 + 0.0382 * 0.3145 + -0.7249 * -1.0206 + 0.1684 * -0.0357 + 1.4514 * 0.4765"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0957269"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydNQRYM5NgVq",
        "outputId": "da9e2d54-5d39-45c4-f08a-28398b4e8966"
      },
      "source": [
        "softmax = torch.nn.functional.softmax(view_1)\n",
        "softmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1308, 0.0900, 0.1161, 0.0541, 0.1322, 0.4769])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAPb0gcBO_Dr"
      },
      "source": [
        "softmax_dimension_changed = softmax.view(1, 1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SjOcUqxPV4q",
        "outputId": "bec9c169-77c8-45b1-cb86-03218b346b08"
      },
      "source": [
        "softmax_dimension_changed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.1308, 0.0900, 0.1161, 0.0541, 0.1322, 0.4769]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHnAcPjZPYtZ"
      },
      "source": [
        "torch_softmax = torch.randn(1,1,12)\n",
        "squeezed = torch_softmax.squeeze().data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnL6Zzd_SSG9",
        "outputId": "86defeef-e48b-4da6-ebac-f4a2c4f782e9"
      },
      "source": [
        "squeezed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7400451 , -0.55089295,  0.46025315,  0.9144252 , -0.09785257,\n",
              "        0.344277  , -0.80282664,  0.05373623,  0.32432762, -0.1767354 ,\n",
              "        0.47543785,  1.2438958 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGQBFoUKSTMz",
        "outputId": "440dc75b-0957-43fa-9d53-3e19420fcf5c"
      },
      "source": [
        "three_d_data = torch.randn(3,4,5)\n",
        "three_d_transpose_1 = three_d_data.transpose(0,1)\n",
        "print(three_d_transpose_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "detDmKXtXM7q",
        "outputId": "86ba4940-31c4-4229-8d46-94632cecd8d0"
      },
      "source": [
        "three_d_data_1 = torch.randn(1, 3, 4)\n",
        "three_d_data_2 = torch.randn(1, 4, 5)\n",
        "batch_multiplication = three_d_data_1.bmm(three_d_data_2)\n",
        "batch_multiplication.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khx6VBr2b8XM",
        "outputId": "bc760606-bb66-474a-ed60-009cd7b73a8f"
      },
      "source": [
        "data_1 = torch.randn(1,3)\n",
        "data_2 = torch.randn(1, 6)\n",
        "torch_concat = torch.cat((data_1, data_2), 1)\n",
        "torch_concat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3439, -0.0776, -2.2502,  0.0083, -0.2465,  0.1979, -0.1296,  0.8472,\n",
              "         -1.5963]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTJUdlBEl01_"
      },
      "source": [
        "one_hot_feature_len = 12\n",
        "list_1 = [1,2,3,5,6]\n",
        "one_hot_feature_vecs = [np.eye(one_hot_feature_len)[list_1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6JSpZ_Rsmr3",
        "outputId": "bbdc1350-853d-43a6-cefa-9106e9342041"
      },
      "source": [
        "one_hot_feature_vecs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvBr9drXs6ex",
        "outputId": "acb67d0f-8753-48d3-a88a-5f3413ed567d"
      },
      "source": [
        "one_hot_feature_vecs[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEh5h9qCtABC",
        "outputId": "8417ccce-5c9e-4144-b89c-3931b8778b23"
      },
      "source": [
        "len(one_hot_feature_vecs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vyl1KDtHAF",
        "outputId": "cdf506bb-46c7-4a56-f5cb-23427793f15d"
      },
      "source": [
        "one_hot_feature_vecs[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLnBtSuZt4IE",
        "outputId": "60687ca0-687c-43ed-dfc0-acb9809742de"
      },
      "source": [
        "data_1 = [np.random.randn(5,12)]\n",
        "data_2 = [np.random.randn(6,12)]\n",
        "data_3 = [[1,2,3,4]]\n",
        "tensor_1 = torch.FloatTensor(data_1)\n",
        "tensor_2 = torch.FloatTensor(data_2)\n",
        "tensor_3 = torch.LongTensor(data_3)\n",
        "\n",
        "print(tensor_1.shape, tensor_2.shape, tensor_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 12]) torch.Size([1, 6, 12]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6tNzC7hv6uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9307da4d-8220-4c98-bd31-6b7eb9ea840e"
      },
      "source": [
        "for n in 'SPPPP':\n",
        "  print('the tokens:', n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the tokens: S\n",
            "the tokens: P\n",
            "the tokens: P\n",
            "the tokens: P\n",
            "the tokens: P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_gakjnjeton",
        "outputId": "4f93b407-d16b-4e49-8848-7db61991f407"
      },
      "source": [
        "[word_dict[n] for n in 'SPPPP']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuNPOUGCfSoW",
        "outputId": "97df7352-ac59-4696-acdd-7c6f7df09d23"
      },
      "source": [
        "word_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E': 6,\n",
              " 'P': 2,\n",
              " 'S': 1,\n",
              " 'a': 0,\n",
              " 'beer': 5,\n",
              " 'bier': 8,\n",
              " 'ein': 4,\n",
              " 'i': 3,\n",
              " 'ich': 7,\n",
              " 'mochte': 9,\n",
              " 'want': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osMNhLoTfVKD",
        "outputId": "e931a534-4d72-496b-933c-383929657c8f"
      },
      "source": [
        "[np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x39A8ysOg-nL"
      },
      "source": [
        "test_batch = torch.FloatTensor(test_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlnM9zLPhbMX",
        "outputId": "23336d0d-cdbf-400a-80b3-1c2498583220"
      },
      "source": [
        "test_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7QjPgeThcLp",
        "outputId": "d9ec5bf7-2d9a-40b8-81f5-90983354f3b0"
      },
      "source": [
        "with torch.no_grad():\n",
        "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    print(predict, trained_attn)\n",
        "    predict = predict.data.max(1, keepdim=True)[1]\n",
        "    print('----------------')\n",
        "    print('predict max:', predict)\n",
        "    print('----------------')\n",
        "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8267, -2.3255, -2.3715, 11.0052, -2.2676, -0.9088, -0.6616, -2.8130,\n",
            "         -2.6028, -2.4966, -0.8146],\n",
            "        [-0.2528, -2.8321, -2.5537, -0.8825, -2.7480, -0.8570, -0.9594, -2.9348,\n",
            "         -2.5445, -2.7684, 11.2229],\n",
            "        [12.5613, -3.6863, -3.9091,  0.1466, -4.4544,  1.0068,  1.4068, -3.5823,\n",
            "         -5.1494, -4.2938,  0.0228],\n",
            "        [ 1.0194, -3.8277, -3.3679, -0.6344, -3.6223, 12.4761,  0.9680, -2.9967,\n",
            "         -3.4179, -2.6734, -0.6444],\n",
            "        [ 1.2882, -3.0534, -3.7333,  0.1616, -3.0951,  1.1808, 12.6430, -4.2160,\n",
            "         -3.4730, -2.9654,  0.2038]]) [array([3.8584813e-01, 6.0690206e-01, 7.2057997e-03, 3.4049634e-05,\n",
            "       9.9318186e-06], dtype=float32), array([1.4454955e-03, 9.9712330e-01, 1.4296384e-03, 1.3380535e-06,\n",
            "       2.7455897e-07], dtype=float32), array([8.7776704e-12, 9.9465280e-10, 2.6637301e-04, 2.7158523e-01,\n",
            "       7.2814840e-01], dtype=float32), array([4.6995197e-10, 3.4552659e-08, 3.5160258e-03, 3.3630851e-01,\n",
            "       6.6017538e-01], dtype=float32), array([1.1784333e-10, 5.8660197e-09, 4.3165818e-04, 2.5333455e-01,\n",
            "       7.4623376e-01], dtype=float32)]\n",
            "----------------\n",
            "predict max: tensor([[ 3],\n",
            "        [10],\n",
            "        [ 0],\n",
            "        [ 5],\n",
            "        [ 6]])\n",
            "----------------\n",
            "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SJfNJKgjE6G",
        "outputId": "0dcf9cde-bd67-45a5-e05a-47a33f94dc2d"
      },
      "source": [
        "n_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gdLBLxcjJLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd205265-5801-413b-86dd-66a09894c4da"
      },
      "source": [
        "a = torch.randn(2,3,4)\n",
        "b = torch.randn(2,1,1)\n",
        "print('a:', a, 'b:', b)\n",
        "for a_ele, b_ele in zip(a, b):\n",
        "    print(a_ele.shape, b_ele.shape)\n",
        "    print(a_ele.unsqueeze(0).shape, b_ele.unsqueeze(0).shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[[-1.0374, -0.5213,  0.5613, -0.9828],\n",
            "         [-1.1751, -1.2646,  0.0924, -0.6226],\n",
            "         [-0.5083, -0.5982, -0.1997,  1.2964]],\n",
            "\n",
            "        [[ 0.1855,  0.7805, -0.0578, -1.1977],\n",
            "         [-1.8506, -0.1525, -0.3795,  1.0894],\n",
            "         [ 0.3203,  1.6797, -1.4123,  1.1623]]]) b: tensor([[[-0.5432]],\n",
            "\n",
            "        [[-1.1960]]])\n",
            "torch.Size([3, 4]) torch.Size([1, 1])\n",
            "torch.Size([1, 3, 4]) torch.Size([1, 1, 1])\n",
            "torch.Size([3, 4]) torch.Size([1, 1])\n",
            "torch.Size([1, 3, 4]) torch.Size([1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftTk3MOEsmaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}