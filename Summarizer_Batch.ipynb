{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Summarizer_Batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthik-Ragunath/Deep_Learning_Notebooks/blob/master/Summarizer_Batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLeh7AEMuIT"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCmbKbx7T12u",
        "outputId": "4c31449e-b157-4994-8183-3f6f91b506c5"
      },
      "source": [
        "# S: Symbol that shows starting of decoding input\n",
        "# E: Symbol that shows starting of decoding output\n",
        "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, n_class)] # n_class represents one hot encoding length\n",
        "    # outer list of dim 1\n",
        "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, one_hot_encoding_length)]\n",
        "    # outer list is of dimension 1\n",
        "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
        "    print('output_batch:', output_batch)\n",
        "    print('target_batch:', target_batch)\n",
        "    # returns dimension - [[word_len]]\n",
        "    # here too outer list of size 1\n",
        "\n",
        "    # make tensor\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3) \n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        print(\"Hidden Layer Size:\", n_hidden)\n",
        "        # Linear for attention\n",
        "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
        "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
        "\n",
        "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
        "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "\n",
        "        # enc_outputs : [n_step (sequence_len), batch_size, num_directions(=1) * n_hidden], matrix F\n",
        "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden) \n",
        "\n",
        "        trained_attn = []\n",
        "        hidden = enc_hidden\n",
        "        n_step = len(dec_inputs) # n_step - sequence_length\n",
        "        model = torch.empty([n_step, 1, n_class]) # same torch.empty(n_step, 1, n_class) - gives tensor of shape (seq_len, 1, input_feature_size)\n",
        "\n",
        "        # If there are multiple batches just make sure to add an outer for loop\n",
        "        # to traverse through different batches and to maintain 3 dimensions, use unsqueeze(batch_dim)\n",
        "        for i in range(n_step):  # each time step\n",
        "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
        "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden) # unsqueezing is done to maintain input_shape - shape maintained = (1, batch_size, n_class)\n",
        "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step] # to compute impact of rest of timestamps on one timestamp, \n",
        "                                                                                                         # thats why decoder output is 1 element (unsqueezed) and encoder output is in list \n",
        "            trained_attn.append(attn_weights.squeeze().data.numpy()) # (1,1,num_steps) gets squeezed into numpy array of size (num_steps) where num_steps = sequence_len or time_stamps\n",
        "\n",
        "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
        "            context = attn_weights.bmm(enc_outputs.transpose(0, 1)) # performing batch matrix multiplication\n",
        "            # (1,1,seq_len) * (seq_len, batch_size, n_hidden*n_directions(=1)).transpose(0,1) where n_class reders to features of input based on which one hot encoding is done\n",
        "            # (1,1,seq_len) * (batch_size, seq_len, n_hidden*n_directions(=1)) - we are considering only one batch here, therefore,\n",
        "            # (1,1,seq_len) * (1, seq_len, num_dirns(=1)*n_hidden) = (1, 1, num_dirns(=1)*n_hidden)\n",
        "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            # after squeezing [n_step(=1),batch_size(=1), num_directions(=1)*n_hidden] in 0th dimension - [batch_size(=1), num_directions(=1)*n_hidden]  \n",
        "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
        "            # after squeezing [1,1, num_dirns(=1)*n_hidden] in 0th dimension - [1,  num_dirns(=1)*n_hidden]\n",
        "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
        "            # torch.cat return (1, (num_directions(=1) * n_hidden) + (num_directions(=1) * n_hidden)) = (1, 2 * num_directions(=1) * n_hidden)\n",
        "            # (1, 2 * num_directions(=1) * n_hidden) * (2*num_directions(=1)*n_hidden, n_class) # n_class represents input features used for one hot encoding\n",
        "            # which will return (1, n_class)\n",
        "\n",
        "        # make model shape [n_step, n_class]\n",
        "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
        "        # model overall shape - [seq_len, 1, n_class]\n",
        "        # [seq_len, 1, n_class].transpose(0, 1) returns shape - [1, seq_len, n_class]\n",
        "        # [seq_len, 1, n_class] squeezing on dimension 0 returns (seq_len, n_class) # seq_len is same as n_step or number_of_timestamps\n",
        "\n",
        "\n",
        "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
        "        n_step = len(enc_outputs) # n_step = seq_len\n",
        "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
        "        # dec\n",
        "        for i in range(n_step):\n",
        "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
        "\n",
        "        # Normalize scores to weights in range 0 to 1\n",
        "        return F.softmax(attn_scores).view(1, 1, -1) # gets softmax output from list of size seq_len (time_stamps)\n",
        "        # returns dimension of size (1,1,seq_len)\n",
        "\n",
        "\n",
        "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
        "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
        "        # attn = nn.Linear(n_hidden, n_hidden) - enc_output = (batch_size, n_hidden * num_dirns) - dec_output = (Batch_size, n_hidden * num_dirns)\n",
        "        # (batch_size, n_hidden*num_dirns) * (n_hidden, n_hidden) = (batch_size, n_hidden)\n",
        "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
        "        # .view(-1) unravels the last dimension which will result in 2 dimesnional tensor becoming 1 dimensional\n",
        "        # .view(-1) will therefore return dimension - vector of dimension batch_size * n_hidden\n",
        "        # dot product will be scalar\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_step = 5 # number of cells(= number of Step)\n",
        "    n_hidden = 128 # number of hidden units in one cell\n",
        "\n",
        "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
        "\n",
        "    word_list = \" \".join(sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "\n",
        "    # print(word_list, word_dict, number_dict)\n",
        "    n_class = len(word_dict)  # vocab list\n",
        "\n",
        "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "    hidden = torch.zeros(1, 1, n_hidden)\n",
        "    # print('n_class:', n_class)\n",
        "    # print('*****************')\n",
        "    # print('hidden:', hidden)\n",
        "    # print('len hidden:', len(hidden[0][0]))\n",
        "\n",
        "    model = Attention()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    input_batch, output_batch, target_batch = make_batch()\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3)\n",
        "\n",
        "    # # Train\n",
        "    for epoch in range(2000):\n",
        "        optimizer.zero_grad()\n",
        "        # clears gradients stored in .grad buffer from previous epoch\n",
        "        output, _ = model(input_batch, hidden, output_batch)\n",
        "        # invokes forward mehod and performs forward pass\n",
        "        loss = criterion(output, target_batch.squeeze(0))\n",
        "        # computing loss\n",
        "        if (epoch + 1) % 400 == 0:\n",
        "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "        loss.backward()\n",
        "        # back-propagates the gradient error to previous layers\n",
        "        optimizer.step()\n",
        "        # updates the parameters\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 128\n",
            "output_batch: [array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
            "target_batch: [[2, 10, 4, 1, 3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0400 cost = 0.000446\n",
            "Epoch: 0800 cost = 0.000144\n",
            "Epoch: 1200 cost = 0.000071\n",
            "Epoch: 1600 cost = 0.000042\n",
            "Epoch: 2000 cost = 0.000027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOVZr5k99kRO",
        "outputId": "73e933d3-1fb6-429e-de49-aac7cb3a9f9a"
      },
      "source": [
        "number_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'P',\n",
              " 1: 'beer',\n",
              " 2: 'i',\n",
              " 3: 'E',\n",
              " 4: 'a',\n",
              " 5: 'ich',\n",
              " 6: 'bier',\n",
              " 7: 'mochte',\n",
              " 8: 'S',\n",
              " 9: 'ein',\n",
              " 10: 'want'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvW5JE9foUP"
      },
      "source": [
        "    # # Test\n",
        "    # test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # test_batch = torch.FloatTensor(test_batch)\n",
        "    # predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    # predict = predict.data.max(1, keepdim=True)[1]\n",
        "    # print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNFUq-k4gO_U",
        "outputId": "33df846a-a703-4f32-83b2-a448273dff1f"
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # create one hot encoding\n",
        "    test_batch = torch.FloatTensor(test_batch)\n",
        "    # convert list of numpy arrays to tensor\n",
        "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    predict = predict.data.max(1, keepdim=True)[1]\n",
        "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "zqqUZEgsfpVY",
        "outputId": "c47ca736-a8be-4432-cf53-8d0a65bcde87"
      },
      "source": [
        "    # Show Attention\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(trained_attn, cmap='viridis')\n",
        "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
        "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIlXX5F_w-T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Qfr_bo_wwH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WrZM_Oegk_W"
      },
      "source": [
        "import pandas as pd\n",
        "english_french_df = pd.read_csv('/content/sample_data/English_French_translation_tab_delimited.csv', delimiter='\\t', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "dAohXTzrgk81",
        "outputId": "13a24e9c-7f2d-4bdd-eb02-0b18a177e1e9"
      },
      "source": [
        "english_french_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
              "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Site map</td>\n",
              "      <td>Plan du site</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Feedback</td>\n",
              "      <td>Rétroaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Credits</td>\n",
              "      <td>Crédits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Français</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>Iqa e</td>\n",
              "      <td>de ie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>La</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ad S</td>\n",
              "      <td>Da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>or</td>\n",
              "      <td>Cerc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>P O</td>\n",
              "      <td>hit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     en                                                 fr\n",
              "0     Changing Lives | Changing Society | How It Wor...  Il a transformé notre vie | Il a transformé la...\n",
              "1                                              Site map                                       Plan du site\n",
              "2                                              Feedback                                        Rétroaction\n",
              "3                                               Credits                                            Crédits\n",
              "4                                              Français                                            English\n",
              "...                                                 ...                                                ...\n",
              "2995                                              Iqa e                                              de ie\n",
              "2996                                                 La                                                  T\n",
              "2997                                               ad S                                                 Da\n",
              "2998                                                 or                                               Cerc\n",
              "2999                                                P O                                                hit\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcgkkn6QUIVp",
        "outputId": "d68ba890-2e93-4eac-9b6a-0a842b68620b"
      },
      "source": [
        "english_french_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['en', 'fr'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUjEtn67UIR-"
      },
      "source": [
        "english_sentences = english_french_df['en']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo8YRo_BUIOZ"
      },
      "source": [
        "french_sentences = english_french_df['fr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npjokVQ4UIKz",
        "outputId": "dc7cfee7-95fe-4e2e-f47c-c486e2ed553d"
      },
      "source": [
        "french_sentence_list = []\n",
        "english_sentence_output_list = []\n",
        "english_sentence_target_list = []\n",
        "\n",
        "french_sentence_hack = []\n",
        "english_sentence_output_hack = []\n",
        "english_sentence_target_hack = []\n",
        "\n",
        "for index, (english_sentence, french_sentence) in enumerate(zip(english_sentences, french_sentences)):\n",
        "    try:\n",
        "        if english_sentence and french_sentence:\n",
        "            english_sentence_output_list.append(\"S \" + english_sentence)\n",
        "            english_sentence_target_list.append(english_sentence + \" E\")\n",
        "            french_sentence_list.append(french_sentence + \" P\")\n",
        "            if len(english_sentence.split()) == 4 and len(french_sentence.split()) == 4:\n",
        "                english_sentence_output_hack.append(\"S \" + english_sentence)\n",
        "                english_sentence_target_hack.append(english_sentence + \" E\")\n",
        "                french_sentence_hack.append(french_sentence + \" P\")\n",
        "    except Exception as e:\n",
        "        print(\"Error raised\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error raised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Q781r-UH-S",
        "outputId": "37c967f1-866e-496d-fcde-e12ede206089"
      },
      "source": [
        "print(english_sentence_output_list[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S Changing Lives | Changing Society | How It Works | Technology Drives Change Home | Concepts | Teachers | Search | Overview | Credits | HHCC Web | Reference | Feedback Virtual Museum of Canada Home Page', 'S Site map', 'S Feedback', 'S Credits', 'S Français', 'S What is light ?', 'S The white light spectrum Codes in the light The electromagnetic spectrum Emission spectra Absorption spectra Light-years Light pollution', 'S The sky of the first inhabitants A contemporary vison of the Universe Astronomy for everyone', 'S Cartoon', 'S Links']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRLc2ZfUH11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d462796-619b-47c8-d8d0-4074dd36e465"
      },
      "source": [
        "len(english_sentence_output_hack)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ9fG85CUHnF"
      },
      "source": [
        "vocabulary_sentences = french_sentence_hack + english_sentence_output_hack + english_sentence_target_hack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kb2Hs1Ygk5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed559b0-e31f-4f56-ae50-195b2589b7ca"
      },
      "source": [
        "len(vocabulary_sentences), len(french_sentence_hack), len(english_sentence_output_hack), len(english_sentence_target_hack)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 27, 27, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_VPPvfxgk27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f657e8-d2c2-4712-fed3-a51e1d391d19"
      },
      "source": [
        "french_sentence_list[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Il a transformé notre vie | Il a transformé la société | Son fonctionnement | La technologie, moteur du changement Accueil | Concepts | Enseignants | Recherche | Aperçu | Collaborateurs | Web HHCC | Ressources | Commentaires Musée virtuel du Canada P',\n",
              " 'Plan du site P',\n",
              " 'Rétroaction P',\n",
              " 'Crédits P']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr87wmAm5v6y"
      },
      "source": [
        "word_list = \" \".join(vocabulary_sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHMAPSrz5v3z"
      },
      "source": [
        "n_class = len(word_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxF7K-Sg7l1W"
      },
      "source": [
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, n_class)] # n_class represents one hot encoding length\n",
        "    # outer list of dim 1\n",
        "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
        "    # returns [np.array-dim(num_words_in_sentence, one_hot_encoding_length)]\n",
        "    # outer list is of dimension 1\n",
        "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
        "    print('output_batch:', output_batch)\n",
        "    print('target_batch:', target_batch)\n",
        "    # returns dimension - [[word_len]]\n",
        "    # here too outer list of size 1\n",
        "\n",
        "    # make tensor\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
        "    # creates tensor of size (1,num_token_sent_1,n_class), (1,num_token_sent_2,n_class), (1,num_token_sent_3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S05eKDCU7lji"
      },
      "source": [
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[[word_dict[n] for n in sentence.split()] for sentence in french_sentence_hack]]]\n",
        "    output_batch = [np.eye(n_class)[[[word_dict[n] for n in sentence.split()] for sentence in english_sentence_output_hack]]]\n",
        "    target_batch = [[word_dict[n] for n in sentence.split()] for sentence in english_sentence_target_hack]\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "gL1oKwOp7k6N",
        "outputId": "cd3e7e89-c2f1-4fee-ec61-0e493be53e3e"
      },
      "source": [
        "input_batch, output_batch, target_batch = make_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-39c7e60b58db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-9e1a0637fa06>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrench_sentence_hack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menglish_sentence_output_hack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menglish_sentence_target_hack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 27 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnE-Bre7kqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtP4kjTF7kbK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3u2PQgH5vzy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Dr2du-5vwm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7qlfhBZ5vsm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n04HoDQq5voO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY6_yirC5vik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ZgQRup5vcg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gahPhawN5vX7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEI8cln35vUH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xvyAQOZ5vKd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGxeliXgkzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyLONFZCgkwn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN-Py84ggkm8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4F4usaGgkZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afPYEL0mpv75"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)\n",
        "\n",
        "# rnn = nn.RNN(10, 20, 2) - # number_of_features = 10 (Used for one-hot encoding), hidden_size = 20 (output size), num_layers = 2\n",
        "# input = torch.randn(5, 3, 10) - # number_of_sequences = 5 (input_token_len [Intuitive number of cells]), number_of_batches = 3, input_size = 10 # num_features must be the same as input_size; used for one-hot encoding\n",
        "# h0 = torch.randn(2, 3, 20) - # directions * num_layers = 2, number_of_batches = 3, hidden_size = 20\n",
        "# output, hn = rnn(input, h0) - # output - (L,N,D∗Hout) - (num_sequences = 5, number_of_batches = 3, D*Hout (Dimension * Hidden_Size) = 1*20), hn - (D∗num_layers - (1*2), number_of_batches - 3, Hout (Hidden Size) - 20) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJvVBkPRp4yd",
        "outputId": "fd081349-9bc4-4b7f-b905-fda9155be74b"
      },
      "source": [
        "rnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(10, 20, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_TaKCC5vci",
        "outputId": "3eafae07-b1b5-482e-e02c-966bedfee9eb"
      },
      "source": [
        "input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0831e+00,  1.1682e+00,  2.0543e+00, -1.1602e+00,  1.0265e+00,\n",
              "           7.3769e-01,  4.0249e-01, -7.4208e-01,  2.1492e-01,  7.1503e-01],\n",
              "         [ 1.0265e+00,  2.8302e+00,  9.5309e-01,  8.8380e-01, -8.7740e-01,\n",
              "           1.3232e+00,  9.6722e-02, -1.0835e+00, -1.4574e+00, -9.0026e-01],\n",
              "         [ 2.1591e-01,  1.3157e-01, -6.3713e-01,  9.0262e-01, -5.4343e-01,\n",
              "           4.0305e-01, -1.2223e-02, -6.7788e-01, -8.7928e-01,  6.3687e-01]],\n",
              "\n",
              "        [[-8.1321e-02, -4.0574e-01,  2.0943e-01, -2.0276e-01,  6.2889e-01,\n",
              "          -1.9671e+00,  1.1834e-01, -7.1259e-01, -1.7655e+00,  2.6436e-01],\n",
              "         [ 7.2928e-01,  2.1325e+00,  1.2982e+00, -3.8353e-01, -5.0894e-01,\n",
              "          -3.8734e-01,  1.5055e+00, -2.0847e-01, -1.4812e-01,  7.0768e-01],\n",
              "         [-1.0223e+00, -2.0602e+00,  2.0781e+00, -9.0671e-01, -4.0895e-02,\n",
              "          -2.2190e-01,  3.0300e-01,  9.9097e-01, -5.6988e-01,  5.8662e-02]],\n",
              "\n",
              "        [[-3.6564e-01,  1.1822e+00,  1.0823e-01, -7.5445e-01, -1.0674e+00,\n",
              "           2.3805e+00,  2.1944e-01,  4.9921e-01, -5.2055e-01, -1.2934e+00],\n",
              "         [-1.1463e-02,  5.5235e-01, -1.7442e+00,  6.0407e-01, -9.9931e-01,\n",
              "          -2.2391e-01,  2.5706e-01,  1.7325e+00, -9.0848e-02,  1.2693e-01],\n",
              "         [-2.0427e+00,  2.3673e-01,  8.4605e-01,  2.2844e-01, -1.5144e+00,\n",
              "           1.8815e+00, -1.8379e+00,  1.1027e-01,  1.4516e+00, -9.5869e-01]],\n",
              "\n",
              "        [[ 7.0426e-01,  1.9117e+00, -1.1926e+00,  8.4414e-01,  1.2979e+00,\n",
              "          -2.6090e-01,  1.6821e+00,  2.2245e-01, -1.5491e-01,  3.3697e-02],\n",
              "         [-1.2981e+00, -6.4531e-02, -9.8550e-01, -1.2634e+00,  3.2740e-01,\n",
              "           2.6296e-01, -2.0712e-02, -8.2313e-01,  5.1711e-01,  7.4775e-01],\n",
              "         [ 1.0522e+00, -2.1027e+00,  1.0612e+00, -3.6456e-01,  7.4748e-04,\n",
              "          -1.0480e+00, -1.9398e-01,  5.5248e-02, -3.7262e-01, -7.2969e-01]],\n",
              "\n",
              "        [[-5.8658e-01,  6.9012e-01,  1.5063e+00,  3.9468e-01,  5.7959e-01,\n",
              "          -1.3423e+00,  1.0849e-01,  8.0357e-01,  1.3340e+00, -8.2865e-01],\n",
              "         [-1.6288e-01,  1.1537e+00, -5.7447e-01,  5.4543e-01, -6.2336e-01,\n",
              "           1.3390e+00,  7.6050e-01, -9.3769e-01,  3.7606e-01,  3.1286e-01],\n",
              "         [ 5.6045e-01, -9.9885e-01,  1.4292e-01,  9.9423e-01,  9.6206e-01,\n",
              "          -2.6770e-01, -1.6759e+00, -1.7291e+00,  8.8400e-01,  1.8094e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue9axnly5x6x",
        "outputId": "52c2614a-0ba7-4e90-8ab0-4cd223f2b68b"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqO8ugn50mR",
        "outputId": "d2fc145e-7fe4-4949-b2a0-7b5f769a14a0"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGfHQcfW54HR",
        "outputId": "6700dbc2-e2a6-4ce1-ecc7-1a88f5d74b15"
      },
      "source": [
        "hn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2yXZlbH6ShS"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr-Gpix064t1",
        "outputId": "3fe7ddd1-149e-4146-faeb-80525f1d336d"
      },
      "source": [
        "# linear layer\n",
        "m = nn.Linear(20, 30) # 20 - size of each input sample, 30 - size of each output sample\n",
        "input = torch.randn(128, 20) # 128 - No. of input samples, 20 - size of each input sample\n",
        "output = m(input) # (128 * 20) * (20 * 30) = (128 * 30) - matrix dimension\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydQPGauRQgxW",
        "outputId": "be0d26e8-f9a3-423b-9554-98fe3ece9394"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmEVciPFQi1l",
        "outputId": "18171992-ff6d-4893-dd04-787a4e9afcf5"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm_xGmMLQpIt",
        "outputId": "def36d6c-d75a-42c1-d833-8b266ff4c915"
      },
      "source": [
        "# nn.functional.linear\n",
        "input_matrix = torch.randn(128, 64)\n",
        "output_matrix = torch.randn(192, 64)\n",
        "bias = torch.ones(192)\n",
        "\n",
        "# bias got broadcasted\n",
        "\n",
        "print(input_matrix.shape)\n",
        "print(output_matrix.shape)\n",
        "print(bias.shape)\n",
        "\n",
        "m = nn.functional.linear(input_matrix, output_matrix, bias=bias) # (128 * 64) * (64 * 192) + (1 * 192)\n",
        "print(m.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64])\n",
            "torch.Size([192, 64])\n",
            "torch.Size([192])\n",
            "torch.Size([128, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hHqUNuTrxe"
      },
      "source": [
        "seq_len = 1\n",
        "input_feature_size = 2\n",
        "sample_model = torch.empty([seq_len, 1, input_feature_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au8RY99NXMZE",
        "outputId": "3f84c913-0a78-4536-c1be-604cdf308bdc"
      },
      "source": [
        "type(sample_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9XCS-iMXQGy",
        "outputId": "ae2653da-7f65-4bac-bce2-ac9e03f19cdd"
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unY0eqqWXjit",
        "outputId": "db921800-9c71-47f5-f808-091bd4b1be9d"
      },
      "source": [
        "sample_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBOm-nLTXSZq"
      },
      "source": [
        "sample_model = torch.empty(seq_len, 1, input_feature_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbkYtB75Xbj5",
        "outputId": "180bb55e-3a9e-4814-dcc3-8c5f3cbd1bda"
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9o8ME7eXech",
        "outputId": "0b4f7b30-352b-40b7-ab26-3950f613659c"
      },
      "source": [
        "sample_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8bJojtsXpZR",
        "outputId": "882c9f47-d095-43cd-9e9b-45ac87d9db18"
      },
      "source": [
        "seq_len = 120\n",
        "batches = 3\n",
        "num_input_features = 5 # vocab size for one hot encoding\n",
        "seq_index = 10\n",
        "enc_inputs = torch.randn((120, 3, 5))\n",
        "enc_inputs[seq_index].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "         [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "         [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt8P9IoBb3ed",
        "outputId": "33d2a04c-c0de-405c-8937-ea04dc4aae92"
      },
      "source": [
        "(enc_inputs[seq_index].squeeze(0)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ7ZEECycMVp",
        "outputId": "f332fbba-309c-4521-a8a1-bec55c76bf1e"
      },
      "source": [
        "enc_inputs[seq_index].squeeze(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "        [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "        [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeEN4zBDcXbA",
        "outputId": "651f5a0b-48ee-4bf4-b1c8-811aaa6f7bda"
      },
      "source": [
        "enc_inputs[seq_index].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqV9fZzOci2A",
        "outputId": "1e3c8f0d-7a4d-449c-93a0-7ab7da6a7550"
      },
      "source": [
        "# Performs batch matrix multiplication\n",
        "input = torch.randn(10, 3, 4)\n",
        "mat2 = torch.randn(10, 4, 5)\n",
        "res = torch.bmm(input, mat2)\n",
        "res.size()\n",
        "#torch.Size([10, 3, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c00V18FdkcTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f7ec43-0f27-40b4-b040-cae66d9639c5"
      },
      "source": [
        "input_1 = torch.randn(2,3)\n",
        "input_2 = torch.randn(2,3)\n",
        "view_1 = input_1.view(-1)\n",
        "view_2 = input_2.view(-1)\n",
        "print(view_1, view_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1577, -0.2166,  0.0382, -0.7249,  0.1684,  1.4514]) tensor([ 0.2352, -2.8680,  0.3145, -1.0206, -0.0357,  0.4765])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDfdyWFZMogs",
        "outputId": "89a74a02-ebdb-4280-808e-fad558cbd579"
      },
      "source": [
        "dot_product = torch.dot(view_1, view_2)\n",
        "dot_product"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.0959)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4f7qAW4NB66",
        "outputId": "0e48f084-3ebc-4020-c53b-0c5321325bb6"
      },
      "source": [
        "0.1577 * 0.2352 + -0.2166 * -2.8680 + 0.0382 * 0.3145 + -0.7249 * -1.0206 + 0.1684 * -0.0357 + 1.4514 * 0.4765"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0957269"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydNQRYM5NgVq",
        "outputId": "da9e2d54-5d39-45c4-f08a-28398b4e8966"
      },
      "source": [
        "softmax = torch.nn.functional.softmax(view_1)\n",
        "softmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1308, 0.0900, 0.1161, 0.0541, 0.1322, 0.4769])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAPb0gcBO_Dr"
      },
      "source": [
        "softmax_dimension_changed = softmax.view(1, 1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SjOcUqxPV4q",
        "outputId": "bec9c169-77c8-45b1-cb86-03218b346b08"
      },
      "source": [
        "softmax_dimension_changed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.1308, 0.0900, 0.1161, 0.0541, 0.1322, 0.4769]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHnAcPjZPYtZ"
      },
      "source": [
        "torch_softmax = torch.randn(1,1,12)\n",
        "squeezed = torch_softmax.squeeze().data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnL6Zzd_SSG9",
        "outputId": "86defeef-e48b-4da6-ebac-f4a2c4f782e9"
      },
      "source": [
        "squeezed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7400451 , -0.55089295,  0.46025315,  0.9144252 , -0.09785257,\n",
              "        0.344277  , -0.80282664,  0.05373623,  0.32432762, -0.1767354 ,\n",
              "        0.47543785,  1.2438958 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGQBFoUKSTMz",
        "outputId": "440dc75b-0957-43fa-9d53-3e19420fcf5c"
      },
      "source": [
        "three_d_data = torch.randn(3,4,5)\n",
        "three_d_transpose_1 = three_d_data.transpose(0,1)\n",
        "print(three_d_transpose_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "detDmKXtXM7q",
        "outputId": "86ba4940-31c4-4229-8d46-94632cecd8d0"
      },
      "source": [
        "three_d_data_1 = torch.randn(1, 3, 4)\n",
        "three_d_data_2 = torch.randn(1, 4, 5)\n",
        "batch_multiplication = three_d_data_1.bmm(three_d_data_2)\n",
        "batch_multiplication.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khx6VBr2b8XM",
        "outputId": "bc760606-bb66-474a-ed60-009cd7b73a8f"
      },
      "source": [
        "data_1 = torch.randn(1,3)\n",
        "data_2 = torch.randn(1, 6)\n",
        "torch_concat = torch.cat((data_1, data_2), 1)\n",
        "torch_concat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3439, -0.0776, -2.2502,  0.0083, -0.2465,  0.1979, -0.1296,  0.8472,\n",
              "         -1.5963]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTJUdlBEl01_"
      },
      "source": [
        "one_hot_feature_len = 12\n",
        "list_1 = [1,2,3,5,6]\n",
        "one_hot_feature_vecs = [np.eye(one_hot_feature_len)[list_1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6JSpZ_Rsmr3",
        "outputId": "bbdc1350-853d-43a6-cefa-9106e9342041"
      },
      "source": [
        "one_hot_feature_vecs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvBr9drXs6ex",
        "outputId": "acb67d0f-8753-48d3-a88a-5f3413ed567d"
      },
      "source": [
        "one_hot_feature_vecs[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEh5h9qCtABC",
        "outputId": "8417ccce-5c9e-4144-b89c-3931b8778b23"
      },
      "source": [
        "len(one_hot_feature_vecs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vyl1KDtHAF",
        "outputId": "cdf506bb-46c7-4a56-f5cb-23427793f15d"
      },
      "source": [
        "one_hot_feature_vecs[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLnBtSuZt4IE",
        "outputId": "60687ca0-687c-43ed-dfc0-acb9809742de"
      },
      "source": [
        "data_1 = [np.random.randn(5,12)]\n",
        "data_2 = [np.random.randn(6,12)]\n",
        "data_3 = [[1,2,3,4]]\n",
        "tensor_1 = torch.FloatTensor(data_1)\n",
        "tensor_2 = torch.FloatTensor(data_2)\n",
        "tensor_3 = torch.LongTensor(data_3)\n",
        "\n",
        "print(tensor_1.shape, tensor_2.shape, tensor_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 12]) torch.Size([1, 6, 12]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6tNzC7hv6uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9307da4d-8220-4c98-bd31-6b7eb9ea840e"
      },
      "source": [
        "for n in 'SPPPP':\n",
        "  print('the tokens:', n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the tokens: S\n",
            "the tokens: P\n",
            "the tokens: P\n",
            "the tokens: P\n",
            "the tokens: P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_gakjnjeton",
        "outputId": "4f93b407-d16b-4e49-8848-7db61991f407"
      },
      "source": [
        "[word_dict[n] for n in 'SPPPP']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuNPOUGCfSoW",
        "outputId": "97df7352-ac59-4696-acdd-7c6f7df09d23"
      },
      "source": [
        "word_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E': 6,\n",
              " 'P': 2,\n",
              " 'S': 1,\n",
              " 'a': 0,\n",
              " 'beer': 5,\n",
              " 'bier': 8,\n",
              " 'ein': 4,\n",
              " 'i': 3,\n",
              " 'ich': 7,\n",
              " 'mochte': 9,\n",
              " 'want': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osMNhLoTfVKD",
        "outputId": "e931a534-4d72-496b-933c-383929657c8f"
      },
      "source": [
        "[np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x39A8ysOg-nL"
      },
      "source": [
        "test_batch = torch.FloatTensor(test_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlnM9zLPhbMX",
        "outputId": "23336d0d-cdbf-400a-80b3-1c2498583220"
      },
      "source": [
        "test_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7QjPgeThcLp",
        "outputId": "d9ec5bf7-2d9a-40b8-81f5-90983354f3b0"
      },
      "source": [
        "with torch.no_grad():\n",
        "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    print(predict, trained_attn)\n",
        "    predict = predict.data.max(1, keepdim=True)[1]\n",
        "    print('----------------')\n",
        "    print('predict max:', predict)\n",
        "    print('----------------')\n",
        "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8267, -2.3255, -2.3715, 11.0052, -2.2676, -0.9088, -0.6616, -2.8130,\n",
            "         -2.6028, -2.4966, -0.8146],\n",
            "        [-0.2528, -2.8321, -2.5537, -0.8825, -2.7480, -0.8570, -0.9594, -2.9348,\n",
            "         -2.5445, -2.7684, 11.2229],\n",
            "        [12.5613, -3.6863, -3.9091,  0.1466, -4.4544,  1.0068,  1.4068, -3.5823,\n",
            "         -5.1494, -4.2938,  0.0228],\n",
            "        [ 1.0194, -3.8277, -3.3679, -0.6344, -3.6223, 12.4761,  0.9680, -2.9967,\n",
            "         -3.4179, -2.6734, -0.6444],\n",
            "        [ 1.2882, -3.0534, -3.7333,  0.1616, -3.0951,  1.1808, 12.6430, -4.2160,\n",
            "         -3.4730, -2.9654,  0.2038]]) [array([3.8584813e-01, 6.0690206e-01, 7.2057997e-03, 3.4049634e-05,\n",
            "       9.9318186e-06], dtype=float32), array([1.4454955e-03, 9.9712330e-01, 1.4296384e-03, 1.3380535e-06,\n",
            "       2.7455897e-07], dtype=float32), array([8.7776704e-12, 9.9465280e-10, 2.6637301e-04, 2.7158523e-01,\n",
            "       7.2814840e-01], dtype=float32), array([4.6995197e-10, 3.4552659e-08, 3.5160258e-03, 3.3630851e-01,\n",
            "       6.6017538e-01], dtype=float32), array([1.1784333e-10, 5.8660197e-09, 4.3165818e-04, 2.5333455e-01,\n",
            "       7.4623376e-01], dtype=float32)]\n",
            "----------------\n",
            "predict max: tensor([[ 3],\n",
            "        [10],\n",
            "        [ 0],\n",
            "        [ 5],\n",
            "        [ 6]])\n",
            "----------------\n",
            "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SJfNJKgjE6G",
        "outputId": "0dcf9cde-bd67-45a5-e05a-47a33f94dc2d"
      },
      "source": [
        "n_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gdLBLxcjJLj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}