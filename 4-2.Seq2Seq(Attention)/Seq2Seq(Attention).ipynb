{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Seq2Seq(Attention).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthik-Ragunath/Deep_Learning_Notebooks/blob/master/4-2.Seq2Seq(Attention)/Seq2Seq(Attention).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCmbKbx7T12u",
        "outputId": "aa5b0e4f-9779-41c7-bb2f-a0edfcbf7f09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# code by Tae Hwan Jung @graykode\n",
        "# Reference : https://github.com/hunkim/PyTorchZeroToAll/blob/master/14_2_seq2seq_att.py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# S: Symbol that shows starting of decoding input\n",
        "# E: Symbol that shows starting of decoding output\n",
        "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
        "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
        "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
        "\n",
        "    # make tensor\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        print(\"Hidden Layer Size:\", n_hidden)\n",
        "        # Linear for attention\n",
        "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
        "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
        "\n",
        "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
        "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
        "\n",
        "        # enc_outputs : [n_step (sequence_len), batch_size, num_directions(=1) * n_hidden], matrix F\n",
        "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden) \n",
        "\n",
        "        trained_attn = []\n",
        "        hidden = enc_hidden\n",
        "        n_step = len(dec_inputs) # n_step - sequence_length\n",
        "        model = torch.empty([n_step, 1, n_class]) # same torch.empty(n_step, 1, n_class) - gives tensor of shape (seq_len, 1, input_feature_size)\n",
        "\n",
        "        for i in range(n_step):  # each time step\n",
        "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
        "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden) # unsqueezing is done to maintain input_shape\n",
        "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step] # to compute impact of rest of timestamps on one timestamp, \n",
        "                                                                                                         # thats why decoder output is 1 element (unsqueezed) and encoder output is in list \n",
        "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
        "\n",
        "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
        "            context = attn_weights.bmm(enc_outputs.transpose(0, 1)) # performing batch matrix multiplication\n",
        "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
        "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
        "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
        "\n",
        "        # make model shape [n_step, n_class]\n",
        "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
        "\n",
        "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
        "        n_step = len(enc_outputs) # n_step = seq_len\n",
        "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
        "        # dec\n",
        "        for i in range(n_step):\n",
        "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
        "\n",
        "        # Normalize scores to weights in range 0 to 1\n",
        "        return F.softmax(attn_scores).view(1, 1, -1) # gets softmax output from list of size seq_len / time_stamps\n",
        "\n",
        "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
        "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
        "        # attn = nn.Linear(n_hidden, n_hidden) - enc_output = (batch_size, n_hidden*num_dirns)\n",
        "        # (batch_size, n_hidden*num_dirns) * (n_hidden * n_hidden) = (batch_size * n_hidden)\n",
        "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_step = 5 # number of cells(= number of Step)\n",
        "    n_hidden = 128 # number of hidden units in one cell\n",
        "\n",
        "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
        "\n",
        "    word_list = \" \".join(sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "\n",
        "    # print(word_list, word_dict, number_dict)\n",
        "    n_class = len(word_dict)  # vocab list\n",
        "\n",
        "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "    hidden = torch.zeros(1, 1, n_hidden)\n",
        "    # print('n_class:', n_class)\n",
        "    # print('*****************')\n",
        "    # print('hidden:', hidden)\n",
        "    # print('len hidden:', len(hidden[0][0]))\n",
        "\n",
        "    model = Attention()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # input_batch, output_batch, target_batch = make_batch()\n",
        "\n",
        "    # # Train\n",
        "    # for epoch in range(2000):\n",
        "    #     optimizer.zero_grad()\n",
        "    #     output, _ = model(input_batch, hidden, output_batch)\n",
        "\n",
        "    #     loss = criterion(output, target_batch.squeeze(0))\n",
        "    #     if (epoch + 1) % 400 == 0:\n",
        "    #         print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "\n",
        "    # # Test\n",
        "    # test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    # test_batch = torch.FloatTensor(test_batch)\n",
        "    # predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    # predict = predict.data.max(1, keepdim=True)[1]\n",
        "    # print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
        "\n",
        "    # # Show Attention\n",
        "    # fig = plt.figure(figsize=(5, 5))\n",
        "    # ax = fig.add_subplot(1, 1, 1)\n",
        "    # ax.matshow(trained_attn, cmap='viridis')\n",
        "    # ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
        "    # ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
        "    # plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_class: 11\n",
            "*****************\n",
            "hidden: tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "len hidden: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afPYEL0mpv75"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)\n",
        "\n",
        "# rnn = nn.RNN(10, 20, 2) - # number_of_features = 10 (Used for one-hot encoding), hidden_size = 20 (output size), num_layers = 2\n",
        "# input = torch.randn(5, 3, 10) - # number_of_sequences = 5 (input_token_len [Intuitive number of cells]), number_of_batches = 3, input_size = 10 # num_features must be the same as input_size; used for one-hot encoding\n",
        "# h0 = torch.randn(2, 3, 20) - # directions * num_layers = 2, number_of_batches = 3, hidden_size = 20\n",
        "# output, hn = rnn(input, h0) - # output - (L,N,D∗Hout) - (num_sequences = 5, number_of_batches = 3, D*Hout (Dimension * Hidden_Size) = 1*20), hn - (D∗num_layers - (1*2), number_of_batches - 3, Hout (Hidden Size) - 20) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvVBkPRp4yd",
        "outputId": "fd081349-9bc4-4b7f-b905-fda9155be74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(10, 20, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u_TaKCC5vci",
        "outputId": "3eafae07-b1b5-482e-e02c-966bedfee9eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0831e+00,  1.1682e+00,  2.0543e+00, -1.1602e+00,  1.0265e+00,\n",
              "           7.3769e-01,  4.0249e-01, -7.4208e-01,  2.1492e-01,  7.1503e-01],\n",
              "         [ 1.0265e+00,  2.8302e+00,  9.5309e-01,  8.8380e-01, -8.7740e-01,\n",
              "           1.3232e+00,  9.6722e-02, -1.0835e+00, -1.4574e+00, -9.0026e-01],\n",
              "         [ 2.1591e-01,  1.3157e-01, -6.3713e-01,  9.0262e-01, -5.4343e-01,\n",
              "           4.0305e-01, -1.2223e-02, -6.7788e-01, -8.7928e-01,  6.3687e-01]],\n",
              "\n",
              "        [[-8.1321e-02, -4.0574e-01,  2.0943e-01, -2.0276e-01,  6.2889e-01,\n",
              "          -1.9671e+00,  1.1834e-01, -7.1259e-01, -1.7655e+00,  2.6436e-01],\n",
              "         [ 7.2928e-01,  2.1325e+00,  1.2982e+00, -3.8353e-01, -5.0894e-01,\n",
              "          -3.8734e-01,  1.5055e+00, -2.0847e-01, -1.4812e-01,  7.0768e-01],\n",
              "         [-1.0223e+00, -2.0602e+00,  2.0781e+00, -9.0671e-01, -4.0895e-02,\n",
              "          -2.2190e-01,  3.0300e-01,  9.9097e-01, -5.6988e-01,  5.8662e-02]],\n",
              "\n",
              "        [[-3.6564e-01,  1.1822e+00,  1.0823e-01, -7.5445e-01, -1.0674e+00,\n",
              "           2.3805e+00,  2.1944e-01,  4.9921e-01, -5.2055e-01, -1.2934e+00],\n",
              "         [-1.1463e-02,  5.5235e-01, -1.7442e+00,  6.0407e-01, -9.9931e-01,\n",
              "          -2.2391e-01,  2.5706e-01,  1.7325e+00, -9.0848e-02,  1.2693e-01],\n",
              "         [-2.0427e+00,  2.3673e-01,  8.4605e-01,  2.2844e-01, -1.5144e+00,\n",
              "           1.8815e+00, -1.8379e+00,  1.1027e-01,  1.4516e+00, -9.5869e-01]],\n",
              "\n",
              "        [[ 7.0426e-01,  1.9117e+00, -1.1926e+00,  8.4414e-01,  1.2979e+00,\n",
              "          -2.6090e-01,  1.6821e+00,  2.2245e-01, -1.5491e-01,  3.3697e-02],\n",
              "         [-1.2981e+00, -6.4531e-02, -9.8550e-01, -1.2634e+00,  3.2740e-01,\n",
              "           2.6296e-01, -2.0712e-02, -8.2313e-01,  5.1711e-01,  7.4775e-01],\n",
              "         [ 1.0522e+00, -2.1027e+00,  1.0612e+00, -3.6456e-01,  7.4748e-04,\n",
              "          -1.0480e+00, -1.9398e-01,  5.5248e-02, -3.7262e-01, -7.2969e-01]],\n",
              "\n",
              "        [[-5.8658e-01,  6.9012e-01,  1.5063e+00,  3.9468e-01,  5.7959e-01,\n",
              "          -1.3423e+00,  1.0849e-01,  8.0357e-01,  1.3340e+00, -8.2865e-01],\n",
              "         [-1.6288e-01,  1.1537e+00, -5.7447e-01,  5.4543e-01, -6.2336e-01,\n",
              "           1.3390e+00,  7.6050e-01, -9.3769e-01,  3.7606e-01,  3.1286e-01],\n",
              "         [ 5.6045e-01, -9.9885e-01,  1.4292e-01,  9.9423e-01,  9.6206e-01,\n",
              "          -2.6770e-01, -1.6759e+00, -1.7291e+00,  8.8400e-01,  1.8094e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue9axnly5x6x",
        "outputId": "52c2614a-0ba7-4e90-8ab0-4cd223f2b68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqqO8ugn50mR",
        "outputId": "d2fc145e-7fe4-4949-b2a0-7b5f769a14a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGfHQcfW54HR",
        "outputId": "6700dbc2-e2a6-4ce1-ecc7-1a88f5d74b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hn.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2yXZlbH6ShS"
      },
      "source": [
        "# Sample RNN\n",
        "rnn = nn.RNN(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr-Gpix064t1",
        "outputId": "3fe7ddd1-149e-4146-faeb-80525f1d336d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# linear layer\n",
        "m = nn.Linear(20, 30) # 20 - size of each input sample, 30 - size of each output sample\n",
        "input = torch.randn(128, 20) # 128 - No. of input samples, 20 - size of each input sample\n",
        "output = m(input) # (128 * 20) * (20 * 30) = (128 * 30) - matrix dimension\n",
        "print(output.size())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQPGauRQgxW",
        "outputId": "be0d26e8-f9a3-423b-9554-98fe3ece9394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmEVciPFQi1l",
        "outputId": "18171992-ff6d-4893-dd04-787a4e9afcf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm_xGmMLQpIt",
        "outputId": "def36d6c-d75a-42c1-d833-8b266ff4c915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# nn.functional.linear\n",
        "input_matrix = torch.randn(128, 64)\n",
        "output_matrix = torch.randn(192, 64)\n",
        "bias = torch.ones(192)\n",
        "\n",
        "# bias got broadcasted\n",
        "\n",
        "print(input_matrix.shape)\n",
        "print(output_matrix.shape)\n",
        "print(bias.shape)\n",
        "\n",
        "m = nn.functional.linear(input_matrix, output_matrix, bias=bias) # (128 * 64) * (64 * 192) + (1 * 192)\n",
        "print(m.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64])\n",
            "torch.Size([192, 64])\n",
            "torch.Size([192])\n",
            "torch.Size([128, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hHqUNuTrxe"
      },
      "source": [
        "seq_len = 1\n",
        "input_feature_size = 2\n",
        "sample_model = torch.empty([seq_len, 1, input_feature_size])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au8RY99NXMZE",
        "outputId": "3f84c913-0a78-4536-c1be-604cdf308bdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(sample_model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9XCS-iMXQGy",
        "outputId": "ae2653da-7f65-4bac-bce2-ac9e03f19cdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unY0eqqWXjit",
        "outputId": "db921800-9c71-47f5-f808-091bd4b1be9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBOm-nLTXSZq"
      },
      "source": [
        "sample_model = torch.empty(seq_len, 1, input_feature_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbkYtB75Xbj5",
        "outputId": "180bb55e-3a9e-4814-dcc3-8c5f3cbd1bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_model.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9o8ME7eXech",
        "outputId": "0b4f7b30-352b-40b7-ab26-3950f613659c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_model"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.1539e-22,  3.0949e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8bJojtsXpZR",
        "outputId": "882c9f47-d095-43cd-9e9b-45ac87d9db18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seq_len = 120\n",
        "batches = 3\n",
        "num_input_features = 5 # vocab size for one hot encoding\n",
        "seq_index = 10\n",
        "enc_inputs = torch.randn((120, 3, 5))\n",
        "enc_inputs[seq_index].unsqueeze(0)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "         [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "         [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt8P9IoBb3ed",
        "outputId": "33d2a04c-c0de-405c-8937-ea04dc4aae92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(enc_inputs[seq_index].squeeze(0)).shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ7ZEECycMVp",
        "outputId": "f332fbba-309c-4521-a8a1-bec55c76bf1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "enc_inputs[seq_index].squeeze(0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8313,  2.0836, -0.6478,  1.7512, -1.6786],\n",
              "        [ 0.4946, -0.2987, -0.3469,  1.8557, -0.4541],\n",
              "        [ 0.4525,  1.2246, -0.3828,  0.4145, -0.9055]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeEN4zBDcXbA",
        "outputId": "651f5a0b-48ee-4bf4-b1c8-811aaa6f7bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "enc_inputs[seq_index].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqV9fZzOci2A",
        "outputId": "1e3c8f0d-7a4d-449c-93a0-7ab7da6a7550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Performs batch matrix multiplication\n",
        "input = torch.randn(10, 3, 4)\n",
        "mat2 = torch.randn(10, 4, 5)\n",
        "res = torch.bmm(input, mat2)\n",
        "res.size()\n",
        "#torch.Size([10, 3, 5])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c00V18FdkcTK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}