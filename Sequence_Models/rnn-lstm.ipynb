{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout, TimeDistributed\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nimport keras.utils as ku \n\n# set seeds for reproducability\nfrom numpy.random import seed\n\nimport pandas as pd\nimport numpy as np\nimport string, os ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install spacy_hunspell","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom spacy_hunspell import spaCyHunSpell","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\nhunspell = spaCyHunSpell(nlp, ('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/qa-csv/qa.csv', delimiter='\\t', encoding='utf-8', index_col=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Query'] = df['Query'].fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries = list(df['Query'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_updated = []\nfor query in queries:\n    query = query.strip()\n    split_len = len(query.split(' '))\n    if split_len >= 2:\n        queries_updated.append(query)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(queries_updated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = df.drop(['Query'], axis=1)\ndel df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(queries_updated, columns=['Query'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\n# def get_sequence_of_tokens(corpus):\n#     pass\ntokenizer.fit_on_texts(queries_updated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_words = len(tokenizer.word_index) + 1\ntotal_words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences = []\nfor line in queries_updated:\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]\n        input_sequences.append(n_gram_sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\npredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\nfor i, j in zip(predictors, label):\n    print(i, j)\nlabel = ku.to_categorical(label, num_classes=total_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_updated","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_updated_tags = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for query in queries_updated:\n    nlp_text = nlp(query)\n    token_list = []\n    for token in nlp_text:\n        token_list.append(token.pos_)\n    nlp_pos = \" \".join(token_list)\n    queries_updated_tags.append(nlp_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries_updated_tags","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer_pos = Tokenizer()\ntokenizer_pos.fit_on_texts(queries_updated_tags)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_words_pos = len(tokenizer_pos.word_index) + 1\ntotal_words_pos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences_pos = []\nfor line in queries_updated_tags:\n    token_list = tokenizer_pos.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]\n        input_sequences_pos.append(n_gram_sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences_pos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences_pos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_sequence_len = max([len(x) for x in input_sequences_pos])\ninput_sequences_pos = np.array(pad_sequences(input_sequences_pos, maxlen=max_sequence_len, padding='pre'))\npredictors, label = input_sequences_pos[:,:-1],input_sequences_pos[:,-1]\nfor i, j in zip(predictors, label):\n    print(i, j)\nlabel = ku.to_categorical(label, num_classes=total_words_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100))\n    model.add(Dropout(0.1))\n    \n    # Add Output Layer\n    model.add(Dense(total_words, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(max_sequence_len, total_words_pos)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(predictors, label, epochs=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_into_pos_tag(query):\n    nlp_text = nlp(query)\n    token_list = []\n    for token in nlp_text:\n        token_list.append(token.pos_)\n    nlp_pos = \" \".join(token_list)\n    return nlp_pos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    seed_text = convert_into_pos_tag(seed_text)\n    print(seed_text)\n    for _ in range(next_words):\n        token_list = tokenizer_pos.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted_freq = model.predict(token_list)\n        print(predicted_freq)\n        predicted = model.predict_classes(token_list, verbose=0)\n        print(predicted)\n        output_word = \"\"\n        for word,index in tokenizer_pos.word_index.items():\n            if index == predicted:\n                print('index:', index, 'type of index:', type(index), 'predicted:', predicted,  'type of predicted:', type(predicted))\n                output_word = word\n                break\n        seed_text += \" \"+output_word\n    return seed_text.title()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = \"Short\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_text(seed_text, 1, model, max_sequence_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_sequence_len = max([len(x) for x in input_sequences_pos])\ninput_sequences_pos = np.array(pad_sequences(input_sequences_pos, maxlen=max_sequence_len, padding='pre'))\npredictors, label = input_sequences_pos[:,:-1],input_sequences_pos[:,1:]\nfor i, j in zip(predictors, label):\n    print(i, j)\n# print(label)\nlabel = ku.to_categorical(label, num_classes=total_words_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_time_sequenced(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100, return_sequences=True))\n    model.add(Dropout(0.1))\n    \n    # Add Output Layer\n    model.add(TimeDistributed(Dense(total_words, activation='softmax')))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_time_sequenced = create_model_time_sequenced(max_sequence_len, total_words_pos)\nmodel_time_sequenced.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_time_sequenced.fit(predictors, label, epochs=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    seed_text = convert_into_pos_tag(seed_text)\n    print(seed_text)\n    for _ in range(next_words):\n        token_list = tokenizer_pos.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        print('tok list:', token_list)\n        predicted_freq = model.predict(token_list)\n        print(predicted_freq)\n        prediction_probs = []\n        for lev_1 in predicted_freq:\n            for lev_2 in lev_1:\n                print(np.max(lev_2))\n        predicted = model.predict_classes(token_list, verbose=0)\n        print(predicted)\n        output_word = \"\"\n        for pred in predicted:\n            for ind_pred in pred:\n                for word,index in tokenizer_pos.word_index.items():\n                    if index == ind_pred:\n                        output_word = word\n                        break\n        seed_text += \" \"+output_word\n    return seed_text.title()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = \"black long sleeves jerkin coat\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_text(seed_text, 1, model_time_sequenced, max_sequence_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.array([1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a == 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}